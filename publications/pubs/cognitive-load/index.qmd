---
title: Cognitive Load Can Reduce Reason-Giving in a Moral Dumbfounding Task
description: "Collabra: Psycholgy (2023)"
author: 
  - name          : "Cillian McHugh"
    affiliation   : University of Limerick
    corresponding : yes    # Define only one corresponding author
    address       : "University of Limerick, Limerick, Ireland"
    email         : "cillian.mchugh@ul.ie"
  - name          : "Marek McGann"
    affiliation   : Mary Immaculate College
  - name          : "Eric R. Igou"
    affiliation   : University of Limerick
  - name          : "Elaine L. Kinsella"
    affiliation   : University of Limerick
date: '2023-04-03'
aliases:   
  - ../cognitive-load/
bibliography      : ["../../../bib/My Library.bib"]
image: featured.png
categories: 
  - morality
  - moral judgment
  - categorization
  - dual-processes
  - moral dumbfounding
---



>Moral dumbfounding occurs when people defend a moral judgment, without reasons in support of this judgment. The phenomenon has been influential in moral psychology, however, despite its influence, it remains poorly understood. Based on the notion that cognitive load enhances biases and shortcomings in human judgment when elaboration is beneficial, we hypothesized that under cognitive load, people would be less likely to provide reasons for a judgment and more likely to be dumbfounded (or to change their judgment). In a pre-registered study (N = 1686) we tested this prediction. Our findings suggest that cognitive load reduces reason-giving, and increases dumbfounding (but does not lead to changes in judgments). Our results provide new insights into the phenomenon of moral dumbfounding while also advancing theory in moral psychology.


<button type="button" class="btn btn-primary btn-sm" onclick="window.open('https://raw.githubusercontent.com/cillianmiltown/website_quarto/main/publications/cognitive-load/cognitive-load.pdf');" data-inline="true" >PDF</button>
<button type="button" class="btn btn-primary btn-sm" onclick="window.open('https://online.ucpress.edu/collabra/article/9/1/73818/195829/Cognitive-Load-Can-Reduce-Reason-Giving-in-a-Moral');" data-inline="true" >Source Document</button>
<button type="button" class="btn btn-primary btn-sm" onclick="window.open('https://osf.io/fcd5r/');" >OSF</button>


<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<title>Bibliography</title>
</head>
<body>
<div class="csl-bib-body" style="line-height: 2; margin-left: 2em; text-indent:-2em;">
  <div class="csl-entry">McHugh, C., McGann, M., Igou, E. R., &amp; Kinsella, E. L. (2023). Cognitive Load Can Reduce Reason-Giving in a Moral Dumbfounding Task. <i>Collabra: Psychology</i>, <i>9</i>(1), 73818. <a href="https://doi.org/10.1525/collabra.73818">https://doi.org/10.1525/collabra.73818</a></div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1525%2Fcollabra.73818&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Cognitive%20Load%20Can%20Reduce%20Reason-Giving%20in%20a%20Moral%20Dumbfounding%20Task&amp;rft.jtitle=Collabra%3A%20Psychology&amp;rft.stitle=Collabra%3A%20Psychology&amp;rft.volume=9&amp;rft.issue=1&amp;rft.aufirst=Cillian&amp;rft.aulast=McHugh&amp;rft.au=Cillian%20McHugh&amp;rft.au=Marek%20McGann&amp;rft.au=Eric%20R.%20Igou&amp;rft.au=Elaine%20L.%20Kinsella&amp;rft.date=2023-04-03&amp;rft.pages=73818&amp;rft.issn=2474-7394"></span>
</div></body>



```{r analysis-preferences, include=FALSE}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(include = FALSE)

```

```{r S6load_libraries_cogload}
rm(list = ls())
library(citr)
#install.packages("sjstats")
library(plyr)
library(foreign)
library(car)
library(desnum)
library(ggplot2)
library(extrafont)
#devtools::install_github("crsh/papaja")
library(papaja)
#library("dplyr")
library("afex")
library("tibble")
library(scales)
#install.packages("metap")
library(metap)
library(pwr)
library(lsr)
#install.packages("sjstats")
library(sjstats)
library(DescTools)
#inatall.packages("ggstatsplot")
#library(ggstatsplot)
library(VGAM)
library(nnet)
library(mlogit)
library(reshape2)
#install.packages("powerMediation")
library("powerMediation")
library(TOSTER)


#source("load_all_data.R")

#devtools::install_github("benmarwick/wordcountaddin")
#library(wordcountaddin)
#wordcountaddin::text_stats("cogload_1to5_25Sept19.Rmd")
getwd()
#setwd("collabra_manuscript_prep")
```



Moral dumbfounding occurs when people defend a moral judgment even though they cannot provide a reason in support of this judgment [Haidt et al., -@haidt_moral_2000; @haidt_emotional_2001; see also McHugh, et al., -@mchugh_searching_2017a; -@mchugh_reasons_2020]. It has traditionally been seen as evidence for intuitionist and dual-process theories of moral judgment [e.g., @crockett_models_2013; @cushman_multisystem_2010; @cushman_action_2013; @greene_secret_2008; @haidt_emotional_2001; @prinz_passionate_2005; though this narrative has been contested, e.g., @guglielmo_unfounded_2018; Royzman et al., -@royzman_curious_2015]. Despite the influence of moral dumbfounding on the morality literature, the phenomenon is not well understood. Here we present a pre-registered test of one prediction of a dual-process explanation of moral dumbfounding.

# Moral Dumbfounding: A Dual-Process Perspective
Drawing on dual-process theories of reasoning and moral judgment [e.g., @greene_secret_2008; @cushman_action_2013; @brand_dualprocess_2016; @bago_intuitive_2019], we propose that moral dumbfounding occurs as a result of a conflict in dual-processes [@bonner_conflict_2010; @deneys_bias_2012; @deneys_conflict_2008; @evans_resolution_2007; see also @deneys_logic_2019]. In classic dual-process reasoning accounts, conflicts occur when a habitual/intuitive response is different from a response that results from deliberation [@bonner_conflict_2010]. Examples of such conflicts include base rate neglect problems [@bonner_conflict_2010; @deneys_bias_2012; @deneys_conflict_2008; @evans_resolution_2007], the conjunction fallacy [@deneys_bias_2012; @tversky_extensional_1983], and perhaps most relevant to the current discussion, a seemingly irrational but persistent unwillingness to contact various symbolically “contaminated” objects, despite assurances these items are sanitary [e.g., items believed to have had prior contact with: an AIDS victim, someone who had been in a car accident, or a murderer, see Rozin et al., -@rozin_sensitivity_1994; @lerner_when_1999]. We note that the original, unpublished dumbfounding manuscript included tasks closely resembling this final example [Haidt et al., -@haidt_moral_2000]. 

In line with the above, we propose that dumbfounding occurs when a habitual (moral judgment) response is in conflict with a deliberative response. In studies of moral dumbfounding, following an initial judgment, there are typically three responses available to participants: (1) providing a reason or justification for a judgment (henceforth reason-giving); (2) accepting  counter-arguments and rating particular behaviors as “not wrong” (nothing-wrong); (3) maintaining a judgment without justification or reasons (dumbfounding). Both reason-giving and nothing-wrong can be accounted for by existing approaches to moral judgment [e.g., @cushman_action_2013], and while reason-giving is the most common response, dumbfounding is reliably observed [see @mchugh_searching_2017a; @mchugh_reasons_2020] and remains an anomaly.

Drawing on existing theorizing [@cushman_action_2013; @haidt_emotional_2001; McHugh et al., -@mchugh_moral_2022], we assume that making a moral judgment is an intuitive/habitual response involving relatively little deliberation, while reason-giving requires greater deliberation (a deliberative response). In this view, conflict occurs when deliberation fails to identify reasons for a judgment, and its resolution depends on the availability of cognitive resources for deliberation – further deliberation may identify relevant reasons. Alternatively, participants may resolve the conflict by accepting the arguments presented and changing their judgment (nothing-wrong). We propose that dumbfounding is observed when this conflict cannot be resolved. We hypothesize that nothing-wrong involves more deliberation than dumbfounding but less deliberation than reason-giving. The hypothesized relative amounts of deliberation for each response are outlined in Figure 1. We note that this explanation is not unique to dual-process approaches, but is also consistent with a unimodal [@kruglanski_intuitive_2011] or categorization [@mchugh_moral_2022] approaches, both of which predict that lower processing capacity reduces reason-giving, and increases dumbfounding.


![Hypothesized relationship between deliberation and responses in the dumbfounding paradigm](img/responses_figure4.jpg){ width=250 margin=auto }


This account of moral dumbfounding affords a clear testable hypothesis: under manipulations that affect the availability of resources for deliberation, responses in the moral dumbfounding paradigm should evidence variation in frequency of deliberative versus habitual responses. Cognitive load manipulations – such as completing an attention/memory task simultaneously with a primary task – have been shown to inhibit deliberative responding [@deneys_conflict_2008; @evans_rapid_2005; @evans_dualprocess_2013; @schmidt_effects_2016]. We have identified reason-giving as involving more deliberation than alternative responses in the dumbfounding paradigm. Thus, we predict that a cognitive load manipulation should inhibit reason-giving in a moral dumbfounding task, leading to an increase in habitual responding, such as dumbfounding or nothing-wrong.


# The Current Research
Our primary prediction is that a cognitive load manipulation will inhibit people’s ability to provide reasons for their judgment, leading to greater habitual responses (either dumbfounding or nothing wrong or both). We present a pre-registered study to test this prediction of a conflict in dual-process explanation of moral dumbfounding.  We experimentally manipulated cognitive load, and predicted that this cognitive load manipulation will inhibit people's ability to provide reasons for their judgment, leading to greater habitual responses (either nothing wrong or dumbfounding or both).

Our cognitive load manipulation involved a secondary task requiring participants to pay attention to a stream of numbers on the screen while completing the moral judgment task. We conducted a series of pilot studies (see Supplement Studies S1 - S5) involving two different memory tasks. The effectiveness of these memory tasks in manipulating cognitive load was unclear, and it is possible that participants could cheat on these memory tasks (particularly for online samples). As such, we selected a cognitive load manipulation that required participants to pay attention to a secondary task (rather than a memory task) while engaged in the primary judgment task [in line with @greene_cognitive_2008].

The data for this study (and all pilot studies), as well as the analysis code for all studies, and full materials for this study including jsPsych script are publicly available at \color{blue}[https://osf.io/fcd5r/?view_only=9fb6e506e53340c189b98453bb2b6eaf](https://osf.io/fcd5r/?view_only=9fb6e506e53340c189b98453bb2b6eaf)\color{black}. This study was pre-registered and the pre-registration is available at \color{blue}[https://aspredicted.org/XZP_UHW](https://aspredicted.org/XZP_UHW)\color{black}. All analyses were conducted in R [@r_core_team_r:_2021], see analysis code for full list of packages.

```{r apriori_logit}
small <- powerMediation::SSizeLogisticCon(.2,(1.49), .05, .8)
med <- powerMediation::SSizeLogisticCon(.2,(3.45), .05, .8)
large <- powerMediation::SSizeLogisticCon(.2,(9), .05, .8)

```


```{r S6loaddatasetStudy6}
#source("~/Dropbox/College/research/Research_general/cog_load/moral_dumbfounding_and_cognitive_load/read_and_sort_raw_data.R")
#source("~/Dropbox/College/research/Research_general/cog_load/moral_dumbfounding_and_cognitive_load/load_study6_data.R")
rm(list = ls())
#load("loaded_data/six.RData")
load("../../../data/six.RData")
study_6$age <- as.numeric(study_6$age)
df3 <- study_6

# haven::write_sav(study_6, "study_6.sav")

#df3$InCS
# df3 <- df3[which(is.na(df3$InCS)==FALSE),]
# df3 <- df3[which(df3$InCS!="null"),]

#df3$InCS <- df3$CS

```

## Method
### Participants and design
This study was a between subjects design.  The dependent variable was rates of reason-giving/dumbfounding (measured using the critical slide with 3 response options: 1: reason-giving; 2: nothing-wrong; 3: dumbfounded response - admission).  The primary independent variable was cognitive load with two levels: present and absent. To manipulate cognitive load, a stream of numbers scrolled across the screen above the question text, and participants were required to pay attention to how many times they saw a given number. The scenario served as a secondary independent variable, we used four scenarios: *Julie and Mark (Incest)*, *Jennifer (Cannibal)*, *Trolley*, *Heinz* (see Supplementary Materials for full text of each).

A total sample of `r length(df3$InCS)` participants (`r sum(df3$gender=="0",na.rm=T)` female, `r sum(df3$gender=="1", na.rm=T)` male, `r sum(df3$gender=="2", na.rm=T)` non-binary, `r sum(df3$gender=="3", na.rm=T)` other, `r sum(df3$gender=="4", na.rm=T)` prefer not to say; *M*~age~ = `r round(mean(df3$age, na.rm=T),digits=2)`, min = `r min(df3$age, na.rm=T)`, max = `r max(df3$age, na.rm=T)`, *SD* = `r round(sd(df3$age, na.rm=T),digits=2)`) started the survey.  Participants in this sample were recruited from Prolific (*n~UK~* = `r sum(df3$country=="UK")`, *n~US~* = `r sum(df3$country=="US")`).[^2]




```{r apriori_power_analyses_reporting}

large <- pwr.chisq.test(w=.35,df=(3-1),sig.level = .05, power=.8)
med   <- pwr.chisq.test(w=.21,df=(3-1),sig.level = .05, power=.8)
small <- pwr.chisq.test(w=.07,df=(3-1),sig.level = .05, power=.8)

round(large$N)
# https://www.real-statistics.com/chi-square-and-f-distributions/effect-size-chi-square/

```


[^2]: A priori power analysis indicated that, for the primary research question (the influence of cognitive load on dumbfounded responding), in order to detect a large effect size (*V* = .35) with 80% power, a sample of *N* = `r round(large$N)` participants was required; in order to detect a medium effect size (*V* = .21) with 80% power a sample of *N* = `r round(med$N)` participants was required; in order to detect a small effect size (*V* = .07) with 80% power a sample of *N* = `r round(small$N)` was required.  

```{r}

x <- study_6
x$attention_check1
x$attention_check2
sum(x$attention_check1!=8)#/4

x$attention_check2!=2|x$attention_check2!=5

sum((x$attention_check2==1|x$attention_check2==4)==FALSE)#/4

x$attention_check1[which((x$attention_check2==1|x$attention_check2==4)==FALSE)]

x$attention_check1[which((x$attention_check2==1|x$attention_check2==4)==FALSE&x$attention_check1!=8)]


att1 <- sum(x$attention_check1!=8,na.rm = T)#/4
att2 <- sum((x$attention_check2==1|x$attention_check2==8)==FALSE,na.rm = T)#/4
att_both <- sum((x$attention_check2==1|x$attention_check2==4)==FALSE&x$attention_check1!=8,na.rm = T)#/4


```


```{r}
x <- study_6

x <- x[which(((x$attention_check2==1|x$attention_check2==5)==FALSE&x$attention_check1!=8)==FALSE),]


table(x$condition)
table(x$InJu1)
sum(is.na(x$InJu1))
table(x$InJu2)
sum(is.na(x$InJu2))
table(x$condition)

x <- x[which(x$InJu1!="null"),]
x <- x[which(is.na(x$InJu1)==FALSE),]
x <- x[which(x$InJu2!="null"),]
x <- x[which(is.na(x$InJu2)==FALSE),]
x <- x[which(is.na(x$InCS)==FALSE),]
x <- x[which(x$InCS!="null"),]



table(x$InJu1)
sum(is.na(x$InJu1))
table(x$InJu2)
sum(is.na(x$InJu2))
table(x$InCS)
sum(is.na(x$InCS))
# 
# x$InJu1 <- as.numeric(x$InJu1)
# x$InJu2 <- as.numeric(x$InJu2)

study_6_clean <- x
df3 <- study_6_clean


df4 <- df3[which(df3$condition=="cog_load"),]
df5 <- df3[which(df3$condition=="control"),]

(length(study_6$gender)-length(study_6_clean$gender))-att_both
length(study_6_clean$gender)
```

Participants who failed both manipulation checks (*n* = `r att_both`) or who had missing data for the measures of interest were removed, leaving a total sample of `r length(df3$InCS)` participants (`r sum(df3$gender=="0",na.rm=T)` female, `r sum(df3$gender=="1", na.rm=T)` male, `r sum(df3$gender=="2", na.rm=T)` non-binary, `r sum(df3$gender=="3", na.rm=T)` other, `r sum(df3$gender=="4", na.rm=T)` prefer not to say; *M*~age~ = `r round(mean(df3$age, na.rm=T),digits=2)`, min = `r min(df3$age, na.rm=T)`, max = `r max(df3$age, na.rm=T)`, *SD* = `r round(sd(df3$age, na.rm=T),digits=2)`), *n~UK~* = `r sum(df3$country=="UK")`, *n~US~* = `r sum(df3$country=="US")`.




### Procedure and materials
Data were collected using an online questionnaire developed with *jsPsych* and distributed with *cognition.run*. Participants were presented with one of four moral scenarios (*Julie and Mark*, *Jennifer*, *Trolley*, *Heinz*, see supplementary materials for full wording), previously used in studies of moral dumbfounding [McHugh et al., -@mchugh_searching_2017a]. Participants rated on a 7-point Likert scale how right or wrong the behavior of the character in the scenario was (where, 1 = *Morally wrong*; 4 = *neutral*; 7 = *Morally right*), and were given an opportunity to provide reasons for their judgment. Following this, participants were presented with a series of counter-arguments, which refute commonly used justifications for rating the behavior as "wrong" (see supplementary materials for full text of scenarios and all counter-arguments).

Dumbfounding was measured using the critical slide [developed by McHugh et al., -@mchugh_searching_2017a]. This contained a statement defending the behavior and a question as to how the behavior could be wrong (e.g., “Julie and Mark’s behavior did not harm anyone, how can there be anything wrong with what they did?”). There were three possible answer options: (a) “It’s wrong, and I can provide a valid reason” (reasons); (b) “It’s wrong, but I can’t think of a reason” (an admission of not having reasons); (c) “There is nothing wrong”. The order of these response options was randomized. Participants who selected (a) were prompted to type a reason. The selecting of an option (b), the admission of not having reasons, was taken to be a dumbfounded response.[^3]
 We note that this measure provides a conservative measure of dumbfounded responding [see @mchugh_searching_2017a for discussion). A key advantage of this measure of dumbfounding is its suitability for use with cognitive load manipulations. The task requirements for each of the three response options are qualitatively the same (selecting a response), eliminating the potential confounding influence of different types of task requirements. Importantly, participants who selected (a) were only prompted to provide a reason after their response to the critical slide had been submitted and recorded, and the survey had proceeded to the next page. Participants did not know they would be required to provide a reason prior to the presentation of this prompt.


[^3]: This measure avoids the potential confounding influence of qualitative differences between different response types; that is, participants indicate whether they can provide reasons for their judgments or not, and this is our measure (not whether or not they actually provide reasons, as this different type of response would not be comparable to a dumbfounded response). 

We included a video stream of numbers scrolling above the question text for our cognitive load manipulation, drawing on @greene_cognitive_2008. The video was wide enough to display 3 numbers at a time, and the numbers scrolled past at a speed of 2 numbers per second. Participants were asked to attend to and report (on a subsequent page) how many times a particular number appeared in the stream, while answering the target question. Following an initial training task, the video was presented while participants made their initial judgments, while they responded to the critical slide, and while they were providing their revised judgments.

Two attention check tasks were included for all participants, these included a brief paragraph of text where instructions for the correct response were embedded within the text. The wording of the text was misleading such that if participants skimmed or only read some of the text they would likely provide an incorrect response.

Participants clicked on the survey link and were randomly assigned to either the experimental condition or the control condition, within which they were randomly presented with one of the four scenarios. The study was complete within 5 minutes.


```{r S6checkingchanges6a, include=FALSE}

length(df3$gender)
table(df3$condition)
table(df3$country)
table(df3$condition,df3$scenario)


```




```{r S6checkingchanges6, include=FALSE}
chisq.test(table(df3$InCS,df3$condition),correct = TRUE)
df3$InJu1 <- as.numeric(as.character(df3$InJu1))
df3$InJu2 <- as.numeric(as.character(df3$InJu2))

t_j1 <- t.test(df3$InJu1 ~ df3$condition)
d_j1 <- cohensD(df3$InJu1 ~ df3$condition)

t_paragraph(df3$InJu1, df3$condition, "initial judgement")
#t_paragraph(one$InJu1, one$condition, "initial judgement")
#t_paragraph(two$InJu1, two$condition, "initial judgement")
#t_paragraph(three$InJu1, three$condition, "initial judgement")


t_j2 <- t.test(df3$InJu2 ~ df3$condition)
d_j2 <- cohensD(df3$InJu2 ~ df3$condition)

t_paragraph(df3$InJu2, df3$condition, "revised judgement")
#t_paragraph(one$InJu1, one$condition, "initial judgement")
#t_paragraph(two$InJu1, two$condition, "initial judgement")
#t_paragraph(three$InJu1, three$condition, "initial judgement")

t_paired_paragraph(df3$InJu1,df3$InJu2, "judgment")
t_j3 <- t.test(df3$InJu1,df3$InJu2,paired = TRUE)
d_j3 <- cohensD(df3$InJu1,df3$InJu2, method = "paired")

numbers2words_cap2(length(df3$Ju1_bin[df3$Ju1_bin=="wrong"]))
numbers2words_cap1(length(df3$InCS[which(df3$InCS=="It's wrong but I can't think of a reason.")]))
numbers2words_cap1(length(df3$InCS[which(df3$InCS=="It's wrong and I can provide a valid reason.")]))
numbers2words(length(df3$InCS[which(df3$InCS=="There is nothing wrong.")]))
```

## Results


```{r S6change in judgement}

# create variables for reporting t.tests
#t <- t.test(df3$InJu1,df3$InJu2, paired = TRUE)

#chisquare test function

custom_chi <- function(x,y){
  a <- length(x)
  b <- length(y)
  c <- rep(1, a)
  d <- rep(2, b)
  e <- c(c,d)
  f <- c(x, y)
  
  g <- data.frame(e,f)
  h <- table(g$e,g$f)
  suppressWarnings(chisq.test(h))
}

c <- suppressWarnings(custom_chi(df3$InJu1,df3$InJu2))

changed_num <- function(x, judgement_1, judgement_2){
  b <- b <- x[which(x$Ju1_bin==judgement_1 & x$Ju2_bin==judgement_2),]
  length(b$Ju1_bin)
  
}

tot_changed_num <- function(x, query){
  
  c <- cbind.data.frame(x$Ju1_bin[which(x$Ju1_bin!=x$Ju2_bin)],x$Ju2_bin[which(x$Ju1_bin!=x$Ju2_bin)])
  colnames(c) <- c("initial_judgement","revised_judgement")
  
  c
  if(query == "table") print(c)
  if(query == "total") print(length(c$initial_judgement))}



tot_changed_table <- function(x){
  
  c <- cbind.data.frame(x$Ju1_bin[which(x$Ju1_bin!=x$Ju2_bin)],x$Ju2_bin[which(x$Ju1_bin!=x$Ju2_bin)])
  colnames(c) <- c("Initial Judgment","Revised Judgment")
  
  c
  }


change_table <- tot_changed_table(df3)
change_table <- table(change_table)
change_table <- as.data.frame(change_table)
change_table <- change_table[which(change_table$Freq!=0),]
change_table <- change_table[order(change_table$Initial.Judgment, change_table$Revised.Judgment), ]
change_table <- `rownames<-`(change_table,NULL)
colnames(change_table) <- c("Initial Judgment","Revised Judgment", "Total Changed")
change_table

```



One thousand three hundred sixty-five participants (`r round(((length(df3$Ju1_bin[df3$Ju1_bin=="wrong"])/length(df3$Ju1_bin))*100), digits=2)`%) rated the behavior described as wrong initially, and `r numbers2words(length(df3$Ju2_bin[df3$Ju2_bin=="wrong"]))` participants (`r round(((length(df3$Ju2_bin[df3$Ju2_bin=="wrong"])/length(df3$Ju2_bin))*100), digits=2)`%) rated the behavior as wrong at the end of the task. Initial ratings (*M* = `r round(mean(df3$InJu1), digits = 2)`, *SD* = `r round(sd(df3$InJu1), digits = 2)`) were significantly more severe than revised ratings (*M* = `r round(mean(df3$InJu2), digits = 2)`, *SD* = `r round(sd(df3$InJu2), digits = 2)`), *t*(`r t_j3$parameter`) = `r t_j3$statistic`, *p* `r paste(p_report(t_j3$p.value))`; *d* = `r round(d_j3, digits=2)`. Inspection of the binned judgments revealed that `r numbers2words(tot_changed_num(df3, "total"))` (`r round((tot_changed_num(df3, "total"))/length(df3$gender)*100, digits = 2)`%) participants changed the valence of their judgments, breakdown of the changes in judgments is in Table 16 (full sample) and Table 17 (by scenario) in the supplementary materials.



```{r S6change,results = 'asis', include=FALSE}


apa_table(
   change_table
   , align = c("l","l", "c")
   , caption = "Changes in Jugment (full sample)"
   #, added_stub_head = "Response to critical slide"
   #, col_spanners = makespanners()
   #, note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r}
# x$InJu1 <- as.numeric(x$InJu1)
# x$InJu2 <- as.numeric(x$InJu2)

TukeyHSD(aov(InJu1 ~ condition+scenario, data = df3))

aov1 <- summary(aov(InJu1 ~ condition*scenario, data = df3))
TukeyHSD(aov(InJu1 ~ condition*scenario, data = df3))
TukeyHSD(aov(InJu1 ~ condition+scenario, data = df3))
aov1
aov1[[1]][["Pr(>F)"]][1]
c(aov1[[1]][["Df"]], " ", ",")[c(1, 6, 5, 4)] # condition
c(aov1[[1]][["Df"]], " ", ",")[c(2, 6, 5, 4)] # scenario
c(aov1[[1]][["Df"]], " ", ",")[c(3, 6, 5, 4)] # interaction
aov1[[1]][["F value"]][1]
aov1[[1]][["F value"]][1]


eta_condition1 <- (aov1[[1]][["Sum Sq"]][1])/((aov1[[1]][["Sum Sq"]][1])+(aov1[[1]][["Sum Sq"]][4]))

eta_scenario1 <- (aov1[[1]][["Sum Sq"]][2])/((aov1[[1]][["Sum Sq"]][2])+(aov1[[1]][["Sum Sq"]][4]))

eta_interaction1 <- (aov1[[1]][["Sum Sq"]][3])/((aov1[[1]][["Sum Sq"]][3])+(aov1[[1]][["Sum Sq"]][4]))


c(aov1[[1]][["Df"]], " ", ",")[c(3, 6, 5, 4)]

round(mean(x$InJu1[which(x$condition=="cog_load")]), digits=2)

tapply(x$InJu1,x$scenario,descriptives)

#aov2 <- summary(aov(as.numeric(InJu2) ~ condition*scenario, data = df3))
```

A 2 $\times$ 2 factorial ANOVA revealed significant differences in initial judgments depending on both condition *F*(`r c(aov1[[1]][["Df"]], " ", ",")[c(1, 6, 5, 4)]`) = `r round(aov1[[1]][["F value"]][1],digits=2)`, *p* `r paste(p_report(aov1[[1]][["Pr(>F)"]][1]))`, partial $\eta$^2^ `r paste(p_report(eta_condition1))`, and scenario *F*(`r c(aov1[[1]][["Df"]], " ", ",")[c(2, 6, 5, 4)]`) = `r round(aov1[[1]][["F value"]][2],digits=2)`, *p* `r paste(p_report(aov1[[1]][["Pr(>F)"]][2]))`, partial $\eta$^2^ `r paste(p_report(eta_scenario1))`. Participants under cognitive load were significantly (*p* < .001) less harsh in their judgments (*M* = `r round(mean(x$InJu1[which(x$condition=="cog_load")]), digits=2)`, *SD* = `r round(sd(x$InJu1[which(x$condition=="cog_load")]), digits=2)`) than those in the control condition (*M* = `r round(mean(x$InJu1[which(x$condition=="control")]), digits=2)`, *SD* = `r round(sd(x$InJu1[which(x$condition=="control")]), digits=2)`). Participants rated *Jennifer* as the most wrong (*M* = `r round(mean(x$InJu1[which(x$scenario=="Jennifer")]), digits=2)`, *SD* = `r round(sd(x$InJu1[which(x$scenario=="Jennifer")]), digits=2)`), followed by *Julie and Mark* (*M* = `r round(mean(x$InJu1[which(x$scenario=="Incest")]), digits=2)`, *SD* = `r round(sd(x$InJu1[which(x$scenario=="Incest")]), digits=2)`, *p* < .001), then *Heinz* (*M* = `r round(mean(x$InJu1[which(x$scenario=="Heinz")]), digits=2)`, *SD* = `r round(sd(x$InJu1[which(x$scenario=="Heinz")]), digits=2)`, *p* < .001), with *Trolley* receiving the least severe judgment (*M* = `r round(mean(x$InJu1[which(x$scenario=="Trolley")]), digits=2)`, *SD* = `r round(sd(x$InJu1[which(x$scenario=="Trolley")]), digits=2)`, *p* < .001). There was no significant condition $\times$ scenario interaction *F*(`r c(aov1[[1]][["Df"]], " ", ",")[c(3, 6, 5, 4)]`) = `r round(aov1[[1]][["F value"]][3],digits=2)`, *p* `r paste(p_report(aov1[[1]][["Pr(>F)"]][3]))`, partial $\eta$^2^ `r paste(p_report(eta_interaction1))`.


```{r}
# x$InJu1 <- as.numeric(x$InJu1)
# x$InJu2 <- as.numeric(x$InJu2)

TukeyHSD(aov(InJu1 ~ condition+scenario, data = df3))

aov1 <- summary(aov(InJu2 ~ condition*scenario, data = df3))
aov1
TukeyHSD(aov(InJu2 ~ condition*scenario, data = df3))
TukeyHSD(aov(InJu2 ~ condition+scenario, data = df3))
aov1
aov1[[1]][["Pr(>F)"]][1]
c(aov1[[1]][["Df"]], " ", ",")[c(1, 6, 5, 4)] # condition
c(aov1[[1]][["Df"]], " ", ",")[c(2, 6, 5, 4)] # scenario
c(aov1[[1]][["Df"]], " ", ",")[c(3, 6, 5, 4)] # interaction
aov1[[1]][["F value"]][1]
aov1[[1]][["F value"]][1]


eta_condition1 <- (aov1[[1]][["Sum Sq"]][1])/((aov1[[1]][["Sum Sq"]][1])+(aov1[[1]][["Sum Sq"]][4]))

eta_scenario1 <- (aov1[[1]][["Sum Sq"]][2])/((aov1[[1]][["Sum Sq"]][2])+(aov1[[1]][["Sum Sq"]][4]))

eta_interaction1 <- (aov1[[1]][["Sum Sq"]][3])/((aov1[[1]][["Sum Sq"]][3])+(aov1[[1]][["Sum Sq"]][4]))


c(aov1[[1]][["Df"]], " ", ",")[c(3, 6, 5, 4)]

round(mean(x$InJu1[which(x$condition=="cog_load")]), digits=2)

tapply(x$InJu2,x$scenario,descriptives)

#aov2 <- summary(aov(as.numeric(InJu2) ~ condition*scenario, data = df3))
```

A 2 $\times$ 2 factorial ANOVA revealed significant differences in revised judgments depending on both condition *F*(`r c(aov1[[1]][["Df"]], " ", ",")[c(1, 6, 5, 4)]`) = `r round(aov1[[1]][["F value"]][1],digits=2)`, *p* `r paste(p_report(aov1[[1]][["Pr(>F)"]][1]))`, partial $\eta$^2^ `r paste(p_report(eta_condition1))`, and scenario *F*(`r c(aov1[[1]][["Df"]], " ", ",")[c(2, 6, 5, 4)]`) = `r round(aov1[[1]][["F value"]][2],digits=2)`, *p* `r paste(p_report(aov1[[1]][["Pr(>F)"]][2]))`, partial $\eta$^2^ `r paste(p_report(eta_scenario1))`. Participants under cognitive load were significantly (*p* < .001) less harsh in their judgments (*M* = `r round(mean(x$InJu2[which(x$condition=="cog_load")]), digits=2)`, *SD* = `r round(sd(x$InJu2[which(x$condition=="cog_load")]), digits=2)`) than those in the control condition (*M* = `r round(mean(x$InJu2[which(x$condition=="control")]), digits=2)`, *SD* = `r round(sd(x$InJu2[which(x$condition=="control")]), digits=2)`). Participants rated *Jennifer* as the most wrong (*M* = `r round(mean(x$InJu2[which(x$scenario=="Jennifer")]), digits=2)`, *SD* = `r round(sd(x$InJu2[which(x$scenario=="Jennifer")]), digits=2)`), followed by *Julie and Mark* (*M* = `r round(mean(x$InJu2[which(x$scenario=="Incest")]), digits=2)`, *SD* = `r round(sd(x$InJu2[which(x$scenario=="Incest")]), digits=2)`, *p* < .001), then *Heinz* (*M* = `r round(mean(x$InJu2[which(x$scenario=="Heinz")]), digits=2)`, *SD* = `r round(sd(x$InJu2[which(x$scenario=="Heinz")]), digits=2)`, *p* = .003), with *Trolley* receiving the least severe judgment (*M* = `r round(mean(x$InJu2[which(x$scenario=="Trolley")]), digits=2)`, *SD* = `r round(sd(x$InJu2[which(x$scenario=="Trolley")]), digits=2)`, *p* < .001). There was no significant condition $\times$ scenario interaction *F*(`r c(aov1[[1]][["Df"]], " ", ",")[c(3, 6, 5, 4)]`) = `r round(aov1[[1]][["F value"]][3],digits=2)`, *p* `r paste(p_report(aov1[[1]][["Pr(>F)"]][3]))`, partial $\eta$^2^ `r paste(p_report(eta_interaction1))`.

Dumbfounding was recorded using the critical slides, participants who selected the admission of not having reasons on the critical slide were identified as dumbfounded.  Four hundred and seventeen participants (`r round((length(df3$InCS[which(df3$InCS=="It's wrong but I can't think of a reason.")])/(length(df3$InCS)))*100, digits=2)`%) selected "It's wrong but I can't think of a reason". One thousand and thirty-two participants (`r round((length(df3$InCS[which(df3$InCS=="It's wrong and I can provide a valid reason.")])/(length(df3$InCS)))*100,digits=2)`%) selected “It's wrong and I can provide a valid reason”; and two hundred and thirty-seven participants (`r round((length(df3$InCS[which(df3$InCS=="There is nothing wrong.")])/(length(df3$InCS)))*100,digits=2)`%) selected “There is nothing wrong”.

```{r}

c <- chisq.test(table(df3$InCS,df3$condition))
w <- sqrt(c[]$statistic/length(df3$gender))
pw <- pwr.chisq.test(w=w,N=length(df3$InCS),df=(3-1),sig.level = .05)

```

A chi-squared test for independence revealed a significant association between experimental condition and response to the critical slide, $\chi$^2^(`r c$parameter`, *N* = `r length(df3$Ju1_bin)`) = `r round(c$statistic, digits=3)`, *p* `r paste(p_report(c$p.value))`, *V* = `r w`, the observed power was `r paste(round(pw$power,digits=3))`.  As predicted, under cognitive load fewer participants (`r sum(df4$InCS=="It's wrong and I can provide a valid reason.",na.rm=T)`; `r sum(df4$InCS=="It's wrong and I can provide a valid reason.",na.rm=T)/length(df4$gender)*100`%) provided reasons than in the control condition (`r sum(df5$InCS=="It's wrong and I can provide a valid reason.",na.rm=T)`; `r sum(df5$InCS=="It's wrong and I can provide a valid reason.",na.rm=T)/length(df5$gender)*100`%), and more participants (`r sum(df4$InCS=="It's wrong but I can't think of a reason.",na.rm=T)`; `r sum(df4$InCS=="It's wrong but I can't think of a reason.",na.rm=T)/length(df4$gender)*100`%) selected "It's wrong but I can't think of a reason." than in the control group (`r sum(df5$InCS=="It's wrong but I can't think of a reason.",na.rm=T)`; `r sum(df5$InCS=="It's wrong but I can't think of a reason.",na.rm=T)/length(df5$gender)*100`%).  The responses to the critical slide for the experimental group (*N* = `r sum(df3$condition=="cog_load")`) and the control group (*N* = `r sum(df3$condition=="control")`) are displayed in Figure\ \@ref(fig:S6ch5S6fig1criticalconditionb).  The observed counts, expected counts and standardised residuals are displayed in Table\ \@ref(tab:S6tab1dumb).  



```{r}

load("../../../data/study6_with_cog_load_performance.RData")

df6 <- study6_with_cog_load_performance
x <- df6

cog_load <- x[which(x$condition=="cog_load"),]

x <- cog_load

x$correct <- x$CS_cog_load_correct*1

x <- 
  x %>% mutate(
    correct = dplyr::recode(
      correct
      , "1" = "Correct"
      , "0" = "Incorrect"))

df6 <- x
c <- chisq.test(table(df6$InCS,df6$correct))
w <- sqrt(c[]$statistic/length(df6$gender))
pw <- pwr.chisq.test(w=w,N=length(df6$InCS),df=(3-1),sig.level = .05)

```

The setup of the jsPsych script ensured we collected response time data for the critical slide as well as the corresponding responses for the cognitive load task (e.g., “how many times did you see the number 3?”). Combining these items allowed us to develop a measure of participants’ performance on the secondary task for the critical slide (we also have this information for the revised judgment, however, a typo in the jsPsych script meant we cannot develop this measure for the initial judgment; we did not record reaction time for the practice task).

For the critical slide, `r sum(x$CS_cog_load_correct)` participants (`r round((sum(x$CS_cog_load_correct)/length(x$gender))*100,digits=2)`%) responded correctly to the secondary task (while for the revised judgment only `r sum(x$inju2_cog_load_correct,na.rm=T)` participants [`r round((sum(x$inju2_cog_load_correct,na.rm=T)/length(x$gender))*100,digits=2)`%] responded correctly to the secondary task). There was no significant difference in responses to the critical slide between participants who provided an accurate response and those who provided an inaccurate response to the secondary task, $\chi$^2^(`r c$parameter`, *N* = `r length(df3$Ju1_bin)`) = `r round(c$statistic, digits=3)`, *p* `r paste(p_report(c$p.value))`, *V* = `r w`, the observed power was `r paste(round(pw$power,digits=3))`, see Table 24 in the supplementary materials.

```{r}


d <- .1017
library(TOSTER)
TOSTER::powerTOSTpaired(.05,.8, low_eqbound_dz = -d, high_eqbound_dz = d)



equivalence_means_test <- function(k1,k2,d){
  TOSTtwo(m1=mean(k1), m2=mean(k2),
          sd1=sd(k1), sd2=sd(k2),
          n1=length(k1), n2=length(k2),
          low_eqbound_d=-d, high_eqbound_d=d, alpha = 0.05)
}


x <- cog_load

x$reason_given <- dplyr::recode(x$InCS,
                                "There is nothing wrong."=0
                                ,"It's wrong but I can't think of a reason."=0
                                ,"It's wrong and I can provide a valid reason."=1
)

#x <- x[which(x$scenario=="Incest"),]

g1 <- x$reason_given[which(x$CS_cog_load_correct==TRUE)]
g2 <- x$reason_given[which(x$CS_cog_load_correct==FALSE)]



equivalence_means_test(g1,g2,d)


eq <- equivalence_means_test(g1,g2,d)
t <- t.test(g1,g2)

```


We additionally conducted an equivalence test to investigate if rates of reason giving varied depending on performance in the cognitive load task. We recoded responses to the critical slide as 1 = *reason given*, 0 = *reason not given*. Our sub sample in the experimental group contained a total of *n* = 826 participants and with this sample we can detect equivalence at the level of *d* = .1017 with 80% power. The equivalence test was non-significant, *t*(`r round(eq$TOST_df)`) = `r round(eq$TOST_t1,digits = 2)`, *p* `r paste(p_report(eq$TOST_p1))` given equivalence bounds of `r round(eq$low_eqbound, digits = 3)` and `r round(eq$high_eqbound, digits = 3)` (on a raw scale) and an alpha of 0.05. The null hypothesis test was non-significant, *t*(`r round(t$parameter)`) = `r round(t$statistic,digits = 2)`, *p* `r paste(p_report(t$p.value))`, given an alpha of 0.05. Thus while we did not find a significant effect for task performance, we cannot conclude that task performance had no effect on reason-giving/response to the critical slide.



```{r}

# 
# 
# df3 <- study_6_clean
# 
# 
# glm(InCS~InJu1, data=x, family = 'binomial')
# 
# df3$InCS <- relevel(df3$InCS, ref = 2)
# 
# glm_model<-lme4::glmer(InCS ~ condition*scenario + (1 | scenario),
#                   data = x
#                   #reflevel = "It's wrong and I can provide a valid reason."
#                   ,family=binomial)
# 
# glm_model
# summary(glm_model)
# 
# 
# 
df3 <- study6_with_cog_load_performance
x <- df3

x$CS_cog_load_correct3 <- as.character(x$CS_cog_load_correct)

z <- x[which(is.na(x$CS_cog_load_correct)),]
y <- x[which(is.na(x$CS_cog_load_correct)==FALSE),]

z$CS_cog_load_correct3 <- rep("control")

y <- 
  y %>% mutate(
    CS_cog_load_correct3 = dplyr::recode(
      CS_cog_load_correct3
      , "TRUE" = "Correct"
      , "FALSE" = "Incorrect"))

x <- rbind(z,y)



x$reason_given <- dplyr::recode(x$InCS,
                                "There is nothing wrong."=0
                                ,"It's wrong but I can't think of a reason."=0
                                ,"It's wrong and I can provide a valid reason."=1
)




df3 <- x

summary(lm(reason_given~CS_cog_load_correct3,x))

apa_results <- apa_print(summary(lm(reason_given~CS_cog_load_correct3,x)))

apa_results$full_result$modelfit
apa_results$full_result$CS_cog_load_correct3Correct
apa_results$full_result$CS_cog_load_correct3Incorrect

DF <- x

class(DF$CS_cog_load_correct3)
DF$CS_cog_load_correct3 <- as.factor(DF$CS_cog_load_correct3)
DF <- within(DF, CS_cog_load_correct3 <- relevel(CS_cog_load_correct3, ref = 2))



apa_results2 <- apa_print(summary(lm(reason_given~CS_cog_load_correct3,DF)))

apa_results2$full_result$CS_cog_load_correct3Incorrect

```

We conducted a follow-up regression analysis to attempt to disentangle the effect of the cognitive load condition vs performance on the cognitive load task, on reason-giving. As expected the overall model significantly predicted reason-giving `r apa_results$full_result$modelfit`. Participants in the control condition were significantly more likely to give reasons than participants who provided the correct response `r apa_results$full_result$CS_cog_load_correct3Correct`, and participants who provided an incorrect response `r apa_results$full_result$CS_cog_load_correct3Incorrect`. There was no significant relationship between rates of reason-giving and whether participants provided a correct or an incorrect response `r apa_results2$full_result$CS_cog_load_correct3Incorrect`

```{r}

x <- study6_with_cog_load_performance

x$CS_cog_load_correct3 <- as.character(x$CS_cog_load_correct)

z <- x[which(is.na(x$CS_cog_load_correct)),]
y <- x[which(is.na(x$CS_cog_load_correct)==FALSE),]

z$CS_cog_load_correct3 <- rep("control")

y <- 
  y %>% mutate(
    CS_cog_load_correct3 = dplyr::recode(
      CS_cog_load_correct3
      , "TRUE" = "Correct"
      , "FALSE" = "Incorrect"))

x <- rbind(z,y)

table(x$CS_cog_load_correct3,x$InCS)
c7 <- chisq.test(table(x$CS_cog_load_correct3,x$InCS))

c7$residuals
```


```{r}
x <- df3
```


```{r}

test <- as.data.frame.matrix((table(df3$InCS,df3$condition)))
`rownames<-`(test, c("nothing wrong","no reason","reasons"))
test <- as.matrix((test))
test1 <- cbind(test[,1],test[,2])
test2 <- `colnames<-`(test1, c("cognitive load","control"))

tb_count_perc <- function(x){
  tc <- table(x$InCS,x$condition)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$condition=="cog_load")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$condition=="control")*100),"%"))
  }
  
tb_count_perc_eng <- function(x){
  tc <- table(x$InCS,x$engaged)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$engaged=="engaged")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$engaged=="not engaged")*100),"%"))
  }
  
test <- tb_count_perc(df3)
test <- as.data.frame(test)
colnames(test) <- c("N","\\%","N","\\%")
  
makespanners <- function(){
  cog_load <- c(2,3)
  control <- c(4,5)
  spans <- list(cog_load,control)
  names(spans) <- c("Cognitive Load","Control")
  spans
}

#test <- tb_count_perc(df3)
#tb_count_perc(df3a)



```


```{r S6tab1dumb1all,results = 'asis', include=FALSE}


apa_table(
   test
   , align = c("l", "c", "c", "c", "c")
   , caption = "Response to the critical slide depending on cognitive load (full sample)"
   #, added_stub_head = "Response to critical slide"
   , col_spanners = makespanners()
   #, note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```

\newpage


```{r}


y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")

z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
test


#y <- table(df3$condition,df3$Dumb_incl_string)
#y <- as.data.frame(y)
#colnames(y) <- c("condition","InCS","Freq")

# z <- as.data.frame(table(df3$condition,df3$Dumb_incl_string)/length(df3$gender)*2)
# perc <- z$Freq
# test <- cbind(y,perc)
# test$condition
# test


ab_graph <- function(){
  a <- df3[which(df3$condition==levels(as.factor(df3$condition))[1]),]
  b <- df3[which(df3$condition==levels(as.factor(df3$condition))[2]),]
  a#levels(as.factor(df3$condition))[1]
  
  ay <- as.data.frame(table(a$InCS,as.character(a$condition)))
  by <- as.data.frame(table(b$InCS,as.character(b$condition)))
  
  aperc <- ay$Freq/length(a$gender)
  ay <- cbind(ay,aperc)
  colnames(ay) <- c("InCS","condition","Freq","perc")
  
  bperc <- by$Freq/length(b$gender)
  by <- cbind(by,bperc)
  colnames(by) <- c("InCS","condition","Freq","perc")
  
  c <- rbind(ay,by)
  
  c
}

test <- ab_graph()



rm(y)
```

```{r}


se_fun <- function(a,b){
  k <- length(a$gender)
  n <- length(b$gender)
  
  pbar <- k/n
  a$pbar <- pbar
  a$se = sqrt(pbar * (1 - pbar)/n)
  a}
# https://www.r-tutor.com/elementary-statistics/interval-estimation/interval-estimate-population-proportion

y <- rbind(
  se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong and I can provide a valid reason."),]
         ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong and I can provide a valid reason."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="cog_load"),])
)

y1 <- y %>% select("InCS","condition","pbar","se")


test1 <- dplyr::left_join(test,y1, by = c("condition","InCS") )

```


```{r}
g <- 
ggplot(test1, aes(x=reorder(InCS), y=perc, fill=factor(condition,labels=c("Cognitive load","Control")))) +
  scale_y_continuous(limits = c(-.03,1),
                     labels = percent_format()
  )+ 
  geom_col(position = "dodge",
           color="black",
           size=.2
  )+
  geom_errorbar(aes(ymin=perc-se, ymax=perc+se), size=.2, width=.2,
               position=position_dodge(.9), color="black" #"#5a5a5a"
                 )+
  geom_text(#family = "Times",
            size=6.2,
            aes( label = scales::percent(perc, accuracy = 1),
                 y= perc ),
            stat= "identity",
            vjust = -1.3,
            position = position_dodge(.9),
            fontface='plain'
            )+
  geom_text(#family = "Times", 
            size=6.2,
            aes(label = format(Freq),
                y= -2.7*(..count../100)/(..count..)),
            stat= "count",
            position = position_dodge(0.9),
            #vjust = -.05,
            fontface='plain'
            ) +
  xlab("Response to Critical Slide") +
  ylab("Percentage of participants selecting each response")+
  scale_x_discrete(labels=c("Reasons", "Dumbfounded","Nothing Wrong")) +
  scale_fill_grey(start = .5, end = .8) +
  labs(fill="Condition") +
  #theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=18
                                ),
        legend.text=element_text(#family="Times",
                                 size=18
                                 ),
        legend.title=element_text(#family="Times",
                                    size=20
                                 ),
        axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=20
                                 ),
        axis.ticks.x = element_blank(),
        axis.title=element_text(#family="Times",
                                  size=24
                                  ),
        strip.text=element_text(#family = "Times",
                                  size = 40
                                  ),
        #strip.background = element_rect(fill = "white"),
        legend.position="right")

g

ggsave("plots/overall.png", g, width = 12, height = 9, units = "in", dpi = 300)

ggsave("plots/overall.jpeg", g, width = 12, height = 9, units = "in", dpi = 300)

```


![Responses to critical slide depending on cognitive load](plots/overall.png){ width=600 margin=auto }

```{r S6ch5S6fig1criticalconditionb, fig.cap="Responses to critical slide depending on cognitive load", include=FALSE}



suppressWarnings(print(g))



```


```{r S6preptableS6}
c <- chisq.test(table(df3$InCS,df3$condition))
rownames(rbind(c$observed,c$expected,c$stdres))



ps <- function(y){
  if(as.numeric(sqrt( y*y) ) >3.3) print(paste0(y,"**"), quote = FALSE)
  else if(as.numeric(sqrt( y*y) ) >1.96) print(paste0(y,"*"), quote = FALSE)
  else print(y)}


x <- c$stdres
x <- round(x, digits = 2)

lapply(x, ps)

#c$stdres <- round(c$stdres,digits=3)
#c$stdres <- ps(c$stdres)

ps(x[1])
ps(x[2])
ps(x[3])

x <- `colnames<-`(
  cbind.data.frame(c(ps(x[1]),ps(x[2]),ps(x[3])),
                   c(ps(x[4]),ps(x[5]),ps(x[6]))),
  c("cog_load","control")
)

rownames(x) <- row.names(c$observed)  

y <- rbind(round(c$observed), round(c$expected, digits = 2))

c(c$stdres[1])


res <- cbind(c("Observed count","","","Expected count","","","Standardised residuals","",""),
      c("Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong"),
      rbind(y,x)
      
      )

row.names(res) <- NULL
colnames(res) <- c("","","Cognitive Load","Control")




```


```{r S6tab1dumb,results = 'asis', include=TRUE}


apa_table(
   res
   , align = c("l", "l", "c", "c", "c")
   , caption = "Observed counts, expected counts, and standardised residuals for each response to the critical slide depending on cognitive load (full sample)"
   #, added_stub_head = "Response to critical slide"
   #, col_spanners = makespanners()
   , note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r}
## breakdown by scenario
df3 <- study_6_clean
df3 <- df3[which(df3$scenario=="Incest"),]
c1 <- chisq.test(table(df3$InCS,df3$condition))
w1 <- sqrt(c1[]$statistic/length(df3$gender))
pw1 <- pwr.chisq.test(w=w1,N=length(df3$InCS),df=(3-1),sig.level = .05)
jm_n <- length(df3$Ju1_bin)


df3 <- study_6_clean
df3 <- df3[which(df3$scenario=="Jennifer"),]
c2 <- chisq.test(table(df3$InCS,df3$condition))
w2 <- sqrt(c2[]$statistic/length(df3$gender))
pw2 <- pwr.chisq.test(w=w2,N=length(df3$InCS),df=(3-1),sig.level = .05)
c_n <- length(df3$Ju1_bin)

df3 <- study_6_clean
df3 <- df3[which(df3$scenario=="Trolley"),]
c3 <- chisq.test(table(df3$InCS,df3$condition))
w3 <- sqrt(c3[]$statistic/length(df3$gender))
pw3 <- pwr.chisq.test(w=w3,N=length(df3$InCS),df=(3-1),sig.level = .05)
t_n <- length(df3$Ju1_bin)

df3 <- study_6_clean
df3 <- df3[which(df3$scenario=="Heinz"),]
c4 <- chisq.test(table(df3$InCS,df3$condition))
w4 <- sqrt(c4[]$statistic/length(df3$gender))
pw4 <- pwr.chisq.test(w=w4,N=length(df3$InCS),df=(3-1),sig.level = .05)
h_n <- length(df3$Ju1_bin)

```

\newpage


This pattern was observed for all scenarios individually with the exception of *Julie and Mark*, which showed no association between experimental condition and cognitive load,  $\chi$^2^(`r c1$parameter`, *N* = `r jm_n`) = `r round(c1$statistic, digits=3)`, *p* `r paste(p_report(c1$p.value))`, *V* = `r w1`, power = `r paste(round(pw1$power,digits=3))`. The association was significant for *Jennifer*  $\chi$^2^(`r c2$parameter`, *N* = `r c_n`) = `r round(c2$statistic, digits=3)`, *p* `r paste(p_report(c2$p.value))`, *V* = `r w2`, power = `r paste(round(pw2$power,digits=3))`, *Trolley*  $\chi$^2^(`r c3$parameter`, *N* = `r t_n`) = `r round(c3$statistic, digits=3)`, *p* `r paste(p_report(c3$p.value))`, *V* = `r w3`, power = `r paste(round(pw3$power,digits=3))`, and Heinz,  $\chi$^2^(`r c4$parameter`, *N* = `r h_n`) = `r round(c4$statistic, digits=3)`, *p* `r paste(p_report(c4$p.value))`, *V* = `r w4`, power = `r paste(round(pw4$power,digits=3))`, see Figure\ \@ref(fig:S6ch5S6fig2criticalconditionb). Supplementary Tables 20-23 show the direction of the effect for each scenario. Under cognitive load, fewer participants provided reasons and more participants provided a dumbfounded response for *Jennifer*, *Trolley*, and *Heinz*



```{r}

df3 <- study_6_clean
x <- df3
x <- x[which(x$condition=="control"),]

table(x$InCS,x$scenario)
c <- chisq.test(table(x$InCS,x$scenario))
c$residuals
```


```{r}

d <- .2025
#d <- .2

d <- .204
TOSTER::powerTOSTpaired(.05,.8, low_eqbound_dz = -d, high_eqbound_dz = d)



equivalence_means_test <- function(k1,k2,d){
  TOSTtwo(m1=mean(k1), m2=mean(k2),
          sd1=sd(k1), sd2=sd(k2),
          n1=length(k1), n2=length(k2),
          low_eqbound_d=-d, high_eqbound_d=d, alpha = 0.05)
}


df3 <- study_6_clean
x <- df3

x$reason_given <- dplyr::recode(x$InCS,
                                "There is nothing wrong."=0
                                ,"It's wrong but I can't think of a reason."=0
                                ,"It's wrong and I can provide a valid reason."=1
)

x <- x[which(x$scenario=="Incest"),]

g1 <- x$reason_given[which(x$condition=="cog_load")]
g2 <- x$reason_given[which(x$condition=="control")]

d

equivalence_means_test(g1,g2,d)


table(x$reason_given,x$condition)
chisq.test(table(x$reason_given,x$condition))

eq <- equivalence_means_test(g1,g2,d)
t <- t.test(g1,g2)

```

Given the null result for *Julie and Mark*, we conducted an exploratory follow-up (not-preregistered) equivalence test, to investigate if our results provided evidence for the absence of an effect for cognitive load. Our key dependent variable was reason-giving, operationalized by participants response to the critical slide. As such, our equivalence test focused specifically on reason-giving, we recoded responses to the critical slide as 1 = *reason given*, 0 = *reason not given*. Our sub sample who responded to the *Julie and Mark* scenario contained a total of *n* = 412 participants. With this sample we can detect equivalence at the level of *d* = .204 with 80% power.

The equivalence test was non-significant, *t*(`r round(eq$TOST_df)`) = `r round(eq$TOST_t1,digits = 2)`, *p* `r paste(p_report(eq$TOST_p1))` given equivalence bounds of `r round(eq$low_eqbound, digits = 3)` and `r round(eq$high_eqbound, digits = 3)` (on a raw scale) and an alpha of 0.05. The null hypothesis test was non-significant, *t*(`r round(t$parameter)`) = `r round(t$statistic,digits = 2)`, *p* `r paste(p_report(t$p.value))`, given an alpha of 0.05. We did not find equivalence at the level of *d* = .204, neither did we find a significant effect.


```{r}
#suppressWarnings(print(g))
```

```{r}
se_fun <- function(a,b){
  k <- length(a$gender)
  n <- length(b$gender)
  
  pbar <- k/n
  a$pbar <- pbar
  a$se = sqrt(pbar * (1 - pbar)/n)
  a}
```


```{r}

df3 <- study_6_clean
#df3$InCS
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]
df3 <- df3[which(df3$scenario=="Incest"),]
y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")
z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
incest <- test


df3 <- study_6_clean
#df3$InCS
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]
df3 <- df3[which(df3$scenario=="Jennifer"),]
y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")
z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
cannibal <- test


df3 <- study_6_clean
#df3$InCS
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]
df3 <- df3[which(df3$scenario=="Trolley"),]
y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")
z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
trolley <- test


df3 <- study_6_clean
#df3$InCS
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]
df3 <- df3[which(df3$scenario=="Heinz"),]
y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")
z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
heinz <- test

test <- rbind.data.frame(incest, cannibal, trolley, heinz)

#y <- table(df3$condition,df3$Dumb_incl_string)
#y <- as.data.frame(y)
#colnames(y) <- c("condition","InCS","Freq")

# z <- as.data.frame(table(df3$condition,df3$Dumb_incl_string)/length(df3$gender)*2)
# perc <- z$Freq
# test <- cbind(y,perc)
# test$condition
# test


ab_graph <- function(){
  a <- df3[which(df3$condition==levels(as.factor(df3$condition))[1]),]
  b <- df3[which(df3$condition==levels(as.factor(df3$condition))[2]),]
  a#levels(as.factor(df3$condition))[1]
  
  ay <- as.data.frame(table(a$InCS,as.character(a$condition)))
  by <- as.data.frame(table(b$InCS,as.character(b$condition)))
  
  aperc <- ay$Freq/length(a$gender)
  ay <- cbind(ay,aperc)
  colnames(ay) <- c("InCS","condition","Freq","perc")
  
  bperc <- by$Freq/length(b$gender)
  by <- cbind(by,bperc)
  colnames(by) <- c("InCS","condition","Freq","perc")
  
  c <- rbind(ay,by)
  
  c
}

df3 <- study_6_clean
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]
df3 <- df3[which(df3$scenario=="Incest"),]
test1 <- ab_graph()
test1$scenario <- rep("Julie and Mark",length(test1$InCS))
x <- df3
y <- rbind(
  se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong and I can provide a valid reason."),]
         ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong and I can provide a valid reason."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="cog_load"),])
)

y1 <- y %>% select("InCS","condition","pbar","se")
test2 <- dplyr::left_join(test1,y1, by = c("condition","InCS") )
incest <- test2

df3 <- study_6_clean
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]
df3 <- df3[which(df3$scenario=="Jennifer"),]
test1 <- ab_graph()
test1$scenario <- rep("Jennifer",length(test1$InCS))
x <- df3
y <- rbind(
  se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong and I can provide a valid reason."),]
         ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong and I can provide a valid reason."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="cog_load"),])
)

y1 <- y %>% select("InCS","condition","pbar","se")
test2 <- dplyr::left_join(test1,y1, by = c("condition","InCS") )
cannibal <- test2

df3 <- study_6_clean
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]
df3 <- df3[which(df3$scenario=="Trolley"),]
test1 <- ab_graph()
test1$scenario <- rep("Trolley",length(test1$InCS))
x <- df3
y <- rbind(
  se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong and I can provide a valid reason."),]
         ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong and I can provide a valid reason."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="cog_load"),])
)

y1 <- y %>% select("InCS","condition","pbar","se")
test2 <- dplyr::left_join(test1,y1, by = c("condition","InCS") )
trolley <- test2

df3 <- study_6_clean
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]
df3 <- df3[which(df3$scenario=="Heinz"),]
test1 <- ab_graph()
test1$scenario <- rep("Heinz",length(test1$InCS))
x <- df3
y <- rbind(
  se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong and I can provide a valid reason."),]
         ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong and I can provide a valid reason."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="cog_load"),])
)

y1 <- y %>% select("InCS","condition","pbar","se")
test2 <- dplyr::left_join(test1,y1, by = c("condition","InCS") )
heinz <- test2

df3 <- study_6_clean
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]

test <- rbind.data.frame(incest, cannibal, trolley, heinz)


rm(y)
```


```{r}

g <- ggplot(test, aes(x=InCS, y=perc, fill=factor(condition
                                             ,labels=c("Cognitive load","Control")
                                             ))) +
  facet_wrap(~scenario,scales='free')+
  scale_y_continuous(limits = c(-.05,1),
                     labels = percent_format()
  )+ 
  geom_col(position = "dodge",
           color="black",
           size=.2
  )+
  geom_text(#family = "Times",
            size=4.5,
            aes( label = scales::percent(perc,accuracy = 1),
                 y= perc-.005
                 #, color=factor(scenario)
                 ),
            stat= "identity",
            vjust = -1.3,
            position = position_dodge(.9),
            fontface='plain'
            )+
  geom_text(#family = "Times", 
            size=4.5,
            aes(label = format(Freq),
                y= -3.8*(..count../100)/(..count..)
                #, color=factor(scenario)
                ),
            stat= "count",
            position = position_dodge(0.9),
            #vjust = -.05,
            fontface='plain'
            )+
  geom_errorbar(aes(ymin=perc-se, ymax=perc+se), size=.1, width=.2,
               position=position_dodge(.9), color="black" #"#5a5a5a"
                 )+
  xlab("Response to Critical Slide") +
  ylab("Percentage of participants selecting each response")+
  scale_x_discrete(labels=c("Reasons", "Dumbfounded","Nothing Wrong")) +
  scale_fill_grey(start = .5, end = .8) +
  labs(fill="Condition") +
  # 
  # geom_text(#family = "Times", 
  #           size=4.2,
  #           aes( label = scales::percent(test$perc),
  #                y= test$perc ),
  #           stat= "identity",
  #           vjust = -.5,
  #           position = position_dodge(.9),
  #           fontface='plain'
  #           )+
  #theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=16
                                ),
        legend.text=element_text(#family="Times",
                                 size=12
                                 ),
        legend.title=element_text(#family="Times",
                                    size=14
                                    ),
        axis.text=element_text(#family="Times",
                               colour = "black",
                               size=10
                               ),
        axis.ticks.x = element_blank(),
        axis.title=element_text(#family="Times",
                                size=14
                                ),
        strip.text=element_text(#family = "Times",
                                  size = 18
                                  ,face='bold'
                                  ),
        #  strip.background = element_rect(fill = "white"),
        legend.position="right")


g

ggsave("plots/all_scenarios.png", g, width = 12, height = 9, units = "in", dpi = 300)

ggsave("plots/all_scenarios.jpeg", g, width = 12, height = 9, units = "in", dpi = 300)

```

![Responses to critical slide and for the experimental group and the control group for each scenario](plots/all_scenarios.png){ width=600 margin=auto }

```{r S6ch5S6fig2criticalconditionb, fig.cap="Responses to critical slide and for the experimental group and the control group for each scenario", include=FALSE}

suppressWarnings(print(g))
```

```{r}

#### this didn't work ####
# x <- study_6_clean
# 
# library(nlme)
# library(lme4)
# 
# lme4::glmer()
# 
# x$condition <- as.factor(x$condition)
# x$scenario <- as.factor(x$scenario)
# x$InCS <- as.factor(x$InCS)
# fit <- lme(InCS ~ condition + scenario, data = x)
# summary(fit)
# 
# ### save this for the combined analysis
# glmm = glmer(InCS ~ condition + (1|study), data=x,family=binomial)
# summary(glmm)

```


```{r}
c <- chisq.test(table(df3$InCS,df3$scenario))
w <- sqrt(c[]$statistic/length(df3$gender))
pw <- pwr.chisq.test(w=w,N=length(df3$InCS),df=(6-1),sig.level = .05)

c$residuals

paste(p_report(2*(1-pnorm(sqrt(c$residuals[[6]]^2)))))
paste(p_report(2*(1-pnorm(sqrt(c$residuals[[7]]^2)))))
paste(p_report(2*(1-pnorm(sqrt(c$residuals[[9]]^2)))))
paste(p_report(2*(1-pnorm(sqrt(c$residuals[[11]]^2)))))


c$residuals[[6]]
c$residuals[[7]]
c$residuals[[9]]
c$residuals[[11]]


```

A chi-squared test for independence revealed a significant association between scenario and response to the critical slide, $\chi$^2^(`r c$parameter`, *N* = `r length(df3$Ju1_bin)`) = `r round(c$statistic, digits=3)`, *p* `r paste(p_report(c$p.value))`, *V* = `r w`, the observed power was `r paste(round(pw$power,digits=3))`. Participants were significantly more likely to select "There is nothing wrong" for *Julie and Mark* (*p* `r paste(p_report(2*(1-pnorm(sqrt(c$residuals[[6]]^2)))))`), more likely to provide reasons (*p* `r paste(p_report(2*(1-pnorm(sqrt(c$residuals[[7]]^2)))))`) and less likely to select "There is nothing wrong" (*p* `r paste(p_report(2*(1-pnorm(sqrt(c$residuals[[9]]^2)))))`) for Jennifer, and more likely to be dumbfounded by *Trolley* (*p* `r paste(p_report(2*(1-pnorm(sqrt(c$residuals[[11]]^2)))))`).

```{r}

# 
# 
# df3 <- study_6_clean
# 
# 
# glm(InCS~InJu1, data=x, family = 'binomial')
# 
# df3$InCS <- relevel(df3$InCS, ref = 2)
# 
# glm_model<-lme4::glmer(InCS ~ condition*scenario + (1 | scenario),
#                   data = x
#                   #reflevel = "It's wrong and I can provide a valid reason."
#                   ,family=binomial)
# 
# glm_model
# summary(glm_model)
# 
# 
# 
df3 <- study6_with_cog_load_performance
x <- df3

x$CS_cog_load_correct3 <- as.character(x$CS_cog_load_correct)

z <- x[which(is.na(x$CS_cog_load_correct)),]
y <- x[which(is.na(x$CS_cog_load_correct)==FALSE),]

z$CS_cog_load_correct3 <- rep("control")

y <- 
  y %>% mutate(
    CS_cog_load_correct3 = dplyr::recode(
      CS_cog_load_correct3
      , "TRUE" = "Correct"
      , "FALSE" = "Incorrect"))

x <- rbind(z,y)

df3 <- x


df3a <- mlogit.data(df3, choice = "InCS", shape = "wide")
InCSModel<-mlogit(InCS ~ 1 | 
                    condition+
                     scenario
                   #+
                   #CS_cog_load_correct3
                  ,
                  data = df3a,
                  reflevel = "It's wrong and I can provide a valid reason."
                  )
# InCSModel<-mlogit(InCS ~ 1 | InJu1,
#                   data = df3a,
#                   reflevel = "It's wrong and I can provide a valid reason."
#                   )

# InCSModel<-mlogit(InCS ~ 1 | condition+scenario,
#                   data = df3a,
#                   reflevel = "It's wrong but I can't think of a reason."
#                   )

summary_InCS_model <- summary(InCSModel)

summary_InCS_model



summary_InCS_model <- summary(InCSModel)
summary_InCS_model$lratio$parameter
summary_InCS_model$lratio$statistic
summary_InCS_model$lratio$p.value

InCSModel$coefficients[3]
InCSModel$coefficients[4]

InCSModel$coefficients
summary_InCS_model$CoefTable
summary_InCS_model$CoefTable[13]
cox <- PseudoR2(multinom(InCS~condition*scenario,df3), "all")


round(cox[3])
cox[4]
#PseudoR2(x, "all")
#summary_InCS_model


wald1 <-
  summary_InCS_model$CoefTable[3]^2 /
  summary_InCS_model$CoefTable[13]^2

wald2 <-
  summary_InCS_model$CoefTable[4]^2 /
  summary_InCS_model$CoefTable[14]^2

wald3 <-
  summary_InCS_model$CoefTable[8]^2 /
  summary_InCS_model$CoefTable[18]^2

wald4 <-
  summary_InCS_model$CoefTable[9]^2 /
  summary_InCS_model$CoefTable[19]^2

summary_InCS_model
summary_InCS_model$coefficients[3]
data.frame(exp(InCSModel$coefficients))

exp(InCSModel$coefficients)[3]

exp(InCSModel$coefficients)[4]
a <- exp(confint(InCSModel))
a

c(a[3],a[7])

residuals(InCSModel)
fitted(InCSModel, outcome = F)

c <- summary_InCS_model$lratio$statistic
w <- sqrt(c/length(df3$gender))
pw <- pwr.chisq.test(w=w,N=length(df3$InCS),df=(5),sig.level = .05)

pw$power

revised_PseudoR2s <- function(LogModel) {
  dev <- LogModel$deviance
  nullDev <- LogModel$null.deviance
  modelN <- length(LogModel$fitted.values)
  R.l <- 1 - dev / nullDev
  R.cs <- 1- exp ( -(nullDev - dev) / modelN)
  R.n <- R.cs / ( 1 - ( exp (-(nullDev / modelN))))

  all <- list(hosmer_and_lemeshow = as.numeric(R.l), mcfadden = NA, cox_and_snell = as.numeric(R.cs), nagelkerke = as.numeric(R.n))
  all
}

#logits_rsquared <- glm(InCS~condition+scenario,df3, family = binomial(link = "logit"))
#cox <- revised_PseudoR2s(logits_rsquared)

pw
wald1

pw$power
```

A multinomial logistic regression was conducted to test the effects of cognitive load and scenario on dumbfounded responding. Overall the model was significant, $\chi$^2^(`r summary_InCS_model$lratio$parameter`, *N* = `r length(df3$gender)`) = `r round(summary_InCS_model$lratio$statistic, digits=2)`, *p* `r paste(p_report(summary_InCS_model$lratio$p.value))`, and explained between `r round(cox[3]*100,digits=2)`% (Cox and Snell R square) and `r round(cox[4]*100, digits=2)`% (Nadelkerke R squared) of the variance in responses to the critical slide, the observed power was `r round(pw$power,digits=7)`. Participants in the control condition were significantly less likely to provide a dumbfounded response than to provide reasons, Wald = `r round(wald1,digits=2)`, *p* `r paste(p_report(summary_InCS_model$CoefTable[33]))`, *OR* = `r exp(InCSModel$coefficients)[3]`, 95% CI [`r a[3]`, `r a[13]`], in addition, participants in the control condition were also signifcantly less likely to select "There is nothing wrong", than to provide reasons, Wald = `r round(wald2,digits=2)`, *p* `r paste(p_report(summary_InCS_model$CoefTable[34]))`, *OR* = `r exp(InCSModel$coefficients)[4]`, 95% CI [`r a[4]`, `r a[14]`]. For *Jennifer*, participants were significantly less likely to select "There is nothing wrong" than to provide a reason, Wald = `r round(wald3,digits=2)`, *p* `r paste(p_report(summary_InCS_model$CoefTable[38]))`, *OR* = `r exp(InCSModel$coefficients)[8]`, 95% CI [`r a[8]`, `r a[18]`]; while for *Trolley* participants were significantly more likely to present as dumbfounded than to provide a reason, Wald = `r round(wald4,digits=2)`, *p* `r paste(p_report(summary_InCS_model$CoefTable[39]))`, *OR* = `r exp(InCSModel$coefficients)[9]`, 95% CI [`r a[9]`, `r a[19]`].



```{r}
df3 <- study_6_clean
#df3$InCS
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]

df3 <- df3[which(df3$scenario=="Incest"),]

df4 <- df3[which(df3$condition=="cog_load"),]
df5 <- df3[which(df3$condition=="control"),]

```

```{r S6checkingchanges6aIncest, include=FALSE}

length(df3$gender)
table(df3$condition)
#table(df3$condition,df3$scenario)

```


```{r S6checkingchanges6Incest, include=FALSE}
chisq.test(table(df3$InCS,df3$condition),correct = TRUE)
```


```{r}

test <- as.data.frame.matrix((table(df3$InCS,df3$condition)))
`rownames<-`(test, c("nothing wrong","no reason","reasons"))
test <- as.matrix((test))
test1 <- cbind(test[,1],test[,2])
test2 <- `colnames<-`(test1, c("cognitive load","control"))

tb_count_perc <- function(x){
  tc <- table(x$InCS,x$condition)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$condition=="cog_load")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$condition=="control")*100),"%"))
  }
  
  tb_count_perc_eng <- function(x){
  tc <- table(x$InCS,x$engaged)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$engaged=="engaged")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$engaged=="not engaged")*100),"%"))
  }
  
test <- tb_count_perc(df3)
test <- as.data.frame(test)
colnames(test) <- c("N","\\%","N","\\%")

  makespanners <- function(){
  cog_load <- c(2,3)
  control <- c(4,5)
  spans <- list(cog_load,control)
  names(spans) <- c("Cognitive Load","Control")
  spans
}

#test <- tb_count_perc(df3)
#tb_count_perc(df3a)



```


```{r S6tab1dumb1allIncest,results = 'asis', include=FALSE}


apa_table(
   test
   , align = c("l", "c", "c", "c", "c")
   , caption = "Response to the critical slide depending on cognitive load (Julie and Mark)"
   #, added_stub_head = "Response to critical slide"
   , col_spanners = makespanners()
   #, note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r}


y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")

z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
test


#y <- table(df3$condition,df3$Dumb_incl_string)
#y <- as.data.frame(y)
#colnames(y) <- c("condition","InCS","Freq")

# z <- as.data.frame(table(df3$condition,df3$Dumb_incl_string)/length(df3$gender)*2)
# perc <- z$Freq
# test <- cbind(y,perc)
# test$condition
# test


ab_graph <- function(){
  a <- df3[which(df3$condition==levels(as.factor(df3$condition))[1]),]
  b <- df3[which(df3$condition==levels(as.factor(df3$condition))[2]),]
  a#levels(as.factor(df3$condition))[1]
  
  ay <- as.data.frame(table(a$InCS,as.character(a$condition)))
  by <- as.data.frame(table(b$InCS,as.character(b$condition)))
  
  aperc <- ay$Freq/length(a$gender)
  ay <- cbind(ay,aperc)
  colnames(ay) <- c("InCS","condition","Freq","perc")
  
  bperc <- by$Freq/length(b$gender)
  by <- cbind(by,bperc)
  colnames(by) <- c("InCS","condition","Freq","perc")
  
  c <- rbind(ay,by)
  
  c
}

test <- ab_graph()



rm(y)
```


```{r S6ch5S6fig2criticalconditionbIncest, fig.cap="Responses to critical slide depending on cognitive load (Julie and Mark)", include=FALSE}

ggplot(test, aes(x=reorder(InCS), y=perc, fill=factor(condition,labels=c("Cognitive load","Control")))) +
  scale_y_continuous(limits = c(-.03,1),
                     labels = percent_format()
  )+ 
  geom_col(position = "dodge",
           color="black",
           size=.2
  )+
  geom_text(#family = "Times",
    size=4.2,
    aes( label = scales::percent(perc, accuracy = 1),
         y= perc ),
    stat= "identity",
    vjust = -.5,
    position = position_dodge(.9),
    fontface='plain'
  )+
  geom_text(#family = "Times", 
    size=4.2,
    aes(label = format(Freq),
        y= -3*(..count../100)/(..count..)),
    stat= "count",
    position = position_dodge(0.9),
    #vjust = -.05,
    fontface='plain'
  ) +
  xlab("Response to Critical Slide") +
  ylab("Percentage of participants selecting each response")+
  scale_x_discrete(labels=c("Reasons", "Dumbfounded","Nothing Wrong")) +
  scale_fill_grey(start = .5, end = .8) +
  labs(fill="Condition") +
  #theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
          size=12
        ),
        legend.text=element_text(#family="Times",
          size=8
        ),
        legend.title=element_text(#family="Times",
          size=10
        ),
        axis.text=element_text(#family="Times",
          colour = "black",
          size=8
        ),
        axis.ticks.x = element_blank(),
        axis.title=element_text(#family="Times",
          size=12
        ),
        strip.text=element_text(#family = "Times",
          size = 12
        ),
        #strip.background = element_rect(fill = "white"),
        legend.position="right")






```



```{r}
c <- chisq.test(table(df3$InCS,df3$condition))
rownames(rbind(c$observed,c$expected,c$stdres))



ps <- function(y){
  if(as.numeric(sqrt( y*y) ) >3.3) print(paste0(y,"**"), quote = FALSE)
  else if(as.numeric(sqrt( y*y) ) >1.96) print(paste0(y,"*"), quote = FALSE)
  else print(y)}


x <- c$stdres
x <- round(x, digits = 2)

lapply(x, ps)

#c$stdres <- round(c$stdres,digits=3)
#c$stdres <- ps(c$stdres)

ps(x[1])
ps(x[2])
ps(x[3])

x <- `colnames<-`(
  cbind.data.frame(c(ps(x[1]),ps(x[2]),ps(x[3])),
                   c(ps(x[4]),ps(x[5]),ps(x[6]))),
  c("cog_load","control")
)

rownames(x) <- row.names(c$observed)  

y <- rbind(round(c$observed), round(c$expected, digits = 2))

c(c$stdres[1])


res <- cbind(c("Observed count","","","Expected count","","","Standardised residuals","",""),
      c("Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong"),
      rbind(y,x)
      
      )

row.names(res) <- NULL
colnames(res) <- c("","","Cognitive Load","Control")




```



```{r S6tab1dumbIncest,results = 'asis', include=FALSE}


apa_table(
   res
   , align = c("l", "l", "c", "c", "c")
   , caption = "Observed counts, expected counts, and standardised residuals for each response to the critical slide depending on cognitive load (Julie and Mark)"
   #, added_stub_head = "Response to critical slide"
   #, col_spanners = makespanners()
   , note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r}
df3 <- study_6_clean
#df3$InCS
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]

df3 <- df3[which(df3$scenario=="Jennifer"),]

df4 <- df3[which(df3$condition=="cog_load"),]
df5 <- df3[which(df3$condition=="control"),]

```

```{r S6checkingchanges6aJennifer, include=FALSE}

length(df3$gender)
table(df3$condition)
#table(df3$condition,df3$scenario)

```


```{r S6checkingchanges6Jennifer, include=FALSE}
chisq.test(table(df3$InCS,df3$condition),correct = TRUE)
```


```{r}

test <- as.data.frame.matrix((table(df3$InCS,df3$condition)))
`rownames<-`(test, c("nothing wrong","no reason","reasons"))
test <- as.matrix((test))
test1 <- cbind(test[,1],test[,2])
test2 <- `colnames<-`(test1, c("cognitive load","control"))

tb_count_perc <- function(x){
  tc <- table(x$InCS,x$condition)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$condition=="cog_load")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$condition=="control")*100),"%"))
  }
  
  tb_count_perc_eng <- function(x){
  tc <- table(x$InCS,x$engaged)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$engaged=="engaged")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$engaged=="not engaged")*100),"%"))
  }
  
test <- tb_count_perc(df3)
test <- as.data.frame(test)
colnames(test) <- c("N","\\%","N","\\%")

  makespanners <- function(){
  cog_load <- c(2,3)
  control <- c(4,5)
  spans <- list(cog_load,control)
  names(spans) <- c("Cognitive Load","Control")
  spans
}

#test <- tb_count_perc(df3)
#tb_count_perc(df3a)



```


```{r S6tab1dumb1allJennifer,results = 'asis', include=FALSE}


apa_table(
   test
   , align = c("l", "l", "c", "c", "c")
   , caption = "Response to the critical slide depending on cognitive load (Jennifer)"
   #, added_stub_head = "Response to critical slide"
   , col_spanners = makespanners()
   #, note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r}


y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")

z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
test


#y <- table(df3$condition,df3$Dumb_incl_string)
#y <- as.data.frame(y)
#colnames(y) <- c("condition","InCS","Freq")

# z <- as.data.frame(table(df3$condition,df3$Dumb_incl_string)/length(df3$gender)*2)
# perc <- z$Freq
# test <- cbind(y,perc)
# test$condition
# test


ab_graph <- function(){
  a <- df3[which(df3$condition==levels(as.factor(df3$condition))[1]),]
  b <- df3[which(df3$condition==levels(as.factor(df3$condition))[2]),]
  a#levels(as.factor(df3$condition))[1]
  
  ay <- as.data.frame(table(a$InCS,as.character(a$condition)))
  by <- as.data.frame(table(b$InCS,as.character(b$condition)))
  
  aperc <- ay$Freq/length(a$gender)
  ay <- cbind(ay,aperc)
  colnames(ay) <- c("InCS","condition","Freq","perc")
  
  bperc <- by$Freq/length(b$gender)
  by <- cbind(by,bperc)
  colnames(by) <- c("InCS","condition","Freq","perc")
  
  c <- rbind(ay,by)
  
  c
}

test <- ab_graph()



rm(y)
```


```{r S6ch5S6fig2criticalconditionbJennifer, fig.cap="Responses to critical slide depending on cognitive load (Jennifer)", include=FALSE}


ggplot(test, aes(x=reorder(InCS), y=perc, fill=factor(condition,labels=c("Cognitive load","Control")))) +
  scale_y_continuous(limits = c(-.03,1),
                     labels = percent_format()
  )+ 
  geom_col(position = "dodge",
           color="black",
           size=.2
  )+
  geom_text(#family = "Times",
    size=4.2,
    aes( label = scales::percent(perc, accuracy = 1),
         y= perc ),
    stat= "identity",
    vjust = -.5,
    position = position_dodge(.9),
    fontface='plain'
  )+
  geom_text(#family = "Times", 
    size=4.2,
    aes(label = format(Freq),
        y= -3*(..count../100)/(..count..)),
    stat= "count",
    position = position_dodge(0.9),
    #vjust = -.05,
    fontface='plain'
  ) +
  xlab("Response to Critical Slide") +
  ylab("Percentage of participants selecting each response")+
  scale_x_discrete(labels=c("Reasons", "Dumbfounded","Nothing Wrong")) +
  scale_fill_grey(start = .5, end = .8) +
  labs(fill="Condition") +
  #theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
          size=12
        ),
        legend.text=element_text(#family="Times",
          size=8
        ),
        legend.title=element_text(#family="Times",
          size=10
        ),
        axis.text=element_text(#family="Times",
          colour = "black",
          size=8
        ),
        axis.ticks.x = element_blank(),
        axis.title=element_text(#family="Times",
          size=12
        ),
        strip.text=element_text(#family = "Times",
          size = 12
        ),
        #strip.background = element_rect(fill = "white"),
        legend.position="right")






```



```{r}
c <- chisq.test(table(df3$InCS,df3$condition))
rownames(rbind(c$observed,c$expected,c$stdres))



ps <- function(y){
  if(as.numeric(sqrt( y*y) ) >3.3) print(paste0(y,"**"), quote = FALSE)
  else if(as.numeric(sqrt( y*y) ) >1.96) print(paste0(y,"*"), quote = FALSE)
  else print(y)}


x <- c$stdres
x <- round(x, digits = 2)

lapply(x, ps)

#c$stdres <- round(c$stdres,digits=3)
#c$stdres <- ps(c$stdres)

ps(x[1])
ps(x[2])
ps(x[3])

x <- `colnames<-`(
  cbind.data.frame(c(ps(x[1]),ps(x[2]),ps(x[3])),
                   c(ps(x[4]),ps(x[5]),ps(x[6]))),
  c("cog_load","control")
)

rownames(x) <- row.names(c$observed)  

y <- rbind(round(c$observed), round(c$expected, digits = 2))

c(c$stdres[1])


res <- cbind(c("Observed count","","","Expected count","","","Standardised residuals","",""),
      c("Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong"),
      rbind(y,x)
      
      )

row.names(res) <- NULL
colnames(res) <- c("","","Cognitive Load","Control")




```



```{r S6tab1dumbJennifer,results = 'asis', include=FALSE}


apa_table(
   res
   , align = c("l", "l", "c", "c", "c")
   , caption = "Observed counts, expected counts, and standardised residuals for each response to the critical slide depending on cognitive load (Julie and Mark)"
   #, added_stub_head = "Response to critical slide"
   #, col_spanners = makespanners()
   , note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```

```{r}
df3 <- study_6_clean
#df3$InCS
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]

df3 <- df3[which(df3$scenario=="Trolley"),]

df4 <- df3[which(df3$condition=="cog_load"),]
df5 <- df3[which(df3$condition=="control"),]

```

```{r S6checkingchanges6aTrolley, include=FALSE}

length(df3$gender)
table(df3$condition)
#table(df3$condition,df3$scenario)

```


```{r checkingchanges6Trolley, include=FALSE}
chisq.test(table(df3$InCS,df3$condition),correct = TRUE)
```


```{r}

test <- as.data.frame.matrix((table(df3$InCS,df3$condition)))
`rownames<-`(test, c("nothing wrong","no reason","reasons"))
test <- as.matrix((test))
test1 <- cbind(test[,1],test[,2])
test2 <- `colnames<-`(test1, c("cognitive load","control"))

tb_count_perc <- function(x){
  tc <- table(x$InCS,x$condition)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$condition=="cog_load")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$condition=="control")*100),"%"))
  }
  
  tb_count_perc_eng <- function(x){
  tc <- table(x$InCS,x$engaged)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$engaged=="engaged")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$engaged=="not engaged")*100),"%"))
  }
  

test <- tb_count_perc(df3)
test <- as.data.frame(test)
colnames(test) <- c("N","\\%","N","\\%")

  makespanners <- function(){
  cog_load <- c(2,3)
  control <- c(4,5)
  spans <- list(cog_load,control)
  names(spans) <- c("Cognitive Load","Control")
  spans
}

#test <- tb_count_perc(df3)
#tb_count_perc(df3a)



```


```{r S6tab1dumb1allTrolley,results = 'asis', include=FALSE}


apa_table(
   test
   , align = c("l", "l", "c", "c", "c")
   , caption = "Response to the critical slide depending on cognitive load (Trolley)"
   #, added_stub_head = "Response to critical slide"
   , col_spanners = makespanners()
   #, note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r}


y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")

z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
test


#y <- table(df3$condition,df3$Dumb_incl_string)
#y <- as.data.frame(y)
#colnames(y) <- c("condition","InCS","Freq")

# z <- as.data.frame(table(df3$condition,df3$Dumb_incl_string)/length(df3$gender)*2)
# perc <- z$Freq
# test <- cbind(y,perc)
# test$condition
# test


ab_graph <- function(){
  a <- df3[which(df3$condition==levels(as.factor(df3$condition))[1]),]
  b <- df3[which(df3$condition==levels(as.factor(df3$condition))[2]),]
  a#levels(as.factor(df3$condition))[1]
  
  ay <- as.data.frame(table(a$InCS,as.character(a$condition)))
  by <- as.data.frame(table(b$InCS,as.character(b$condition)))
  
  aperc <- ay$Freq/length(a$gender)
  ay <- cbind(ay,aperc)
  colnames(ay) <- c("InCS","condition","Freq","perc")
  
  bperc <- by$Freq/length(b$gender)
  by <- cbind(by,bperc)
  colnames(by) <- c("InCS","condition","Freq","perc")
  
  c <- rbind(ay,by)
  
  c
}

test <- ab_graph()



rm(y)
```


```{r S6ch5S6fig2criticalconditionbTrolley, fig.cap="Responses to critical slide depending on cognitive load (Trolley)", include=FALSE}


ggplot(test, aes(x=reorder(InCS), y=perc, fill=factor(condition,labels=c("Cognitive load","Control")))) +
  scale_y_continuous(limits = c(-.03,1),
                     labels = percent_format()
  )+ 
  geom_col(position = "dodge",
           color="black",
           size=.2
  )+
  geom_text(#family = "Times",
    size=4.2,
    aes( label = scales::percent(perc, accuracy = 1),
         y= perc ),
    stat= "identity",
    vjust = -.5,
    position = position_dodge(.9),
    fontface='plain'
  )+
  geom_text(#family = "Times", 
    size=4.2,
    aes(label = format(Freq),
        y= -3*(..count../100)/(..count..)),
    stat= "count",
    position = position_dodge(0.9),
    #vjust = -.05,
    fontface='plain'
  ) +
  xlab("Response to Critical Slide") +
  ylab("Percentage of participants selecting each response")+
  scale_x_discrete(labels=c("Reasons", "Dumbfounded","Nothing Wrong")) +
  scale_fill_grey(start = .5, end = .8) +
  labs(fill="Condition") +
  #theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
          size=12
        ),
        legend.text=element_text(#family="Times",
          size=8
        ),
        legend.title=element_text(#family="Times",
          size=10
        ),
        axis.text=element_text(#family="Times",
          colour = "black",
          size=8
        ),
        axis.ticks.x = element_blank(),
        axis.title=element_text(#family="Times",
          size=12
        ),
        strip.text=element_text(#family = "Times",
          size = 12
        ),
        #strip.background = element_rect(fill = "white"),
        legend.position="right")






```



```{r}
c <- chisq.test(table(df3$InCS,df3$condition))
rownames(rbind(c$observed,c$expected,c$stdres))



ps <- function(y){
  if(as.numeric(sqrt( y*y) ) >3.3) print(paste0(y,"**"), quote = FALSE)
  else if(as.numeric(sqrt( y*y) ) >1.96) print(paste0(y,"*"), quote = FALSE)
  else print(y)}


x <- c$stdres
x <- round(x, digits = 2)

lapply(x, ps)

#c$stdres <- round(c$stdres,digits=3)
#c$stdres <- ps(c$stdres)

ps(x[1])
ps(x[2])
ps(x[3])

x <- `colnames<-`(
  cbind.data.frame(c(ps(x[1]),ps(x[2]),ps(x[3])),
                   c(ps(x[4]),ps(x[5]),ps(x[6]))),
  c("cog_load","control")
)

rownames(x) <- row.names(c$observed)  

y <- rbind(round(c$observed), round(c$expected, digits = 2))

c(c$stdres[1])


res <- cbind(c("Observed count","","","Expected count","","","Standardised residuals","",""),
      c("Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong"),
      rbind(y,x)
      
      )

row.names(res) <- NULL
colnames(res) <- c("","","Cognitive Load","Control")




```



```{r S6tab1dumbTrolley,results = 'asis', include=FALSE}


apa_table(
   res
   , align = c("l", "l", "c", "c", "c")
   , caption = "Observed counts, expected counts, and standardised residuals for each response to the critical slide depending on cognitive load (Trolley)"
   #, added_stub_head = "Response to critical slide"
   #, col_spanners = makespanners()
   , note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```

```{r}
df3 <- study_6_clean
#df3$InCS
df3 <- df3[which(is.na(df3$InCS)==FALSE),]
df3 <- df3[which(df3$InCS!="null"),]

df3 <- df3[which(df3$scenario=="Heinz"),]

df4 <- df3[which(df3$condition=="cog_load"),]
df5 <- df3[which(df3$condition=="control"),]

```

```{r S6checkingchanges6aHeinz, include=FALSE}

length(df3$gender)
table(df3$condition)
#table(df3$condition,df3$scenario)

```


```{r S6checkingchanges6Heinz, include=FALSE}
chisq.test(table(df3$InCS,df3$condition),correct = TRUE)
```


```{r}

test <- as.data.frame.matrix((table(df3$InCS,df3$condition)))
`rownames<-`(test, c("nothing wrong","no reason","reasons"))
test <- as.matrix((test))
test1 <- cbind(test[,1],test[,2])
test2 <- `colnames<-`(test1, c("cognitive load","control"))

tb_count_perc <- function(x){
  tc <- table(x$InCS,x$condition)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$condition=="cog_load")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$condition=="control")*100),"%"))
  }
  
  tb_count_perc_eng <- function(x){
  tc <- table(x$InCS,x$engaged)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$engaged=="engaged")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$engaged=="not engaged")*100),"%"))
  }
  
test <- tb_count_perc(df3)
test <- as.data.frame(test)
colnames(test) <- c("N","\\%","N","\\%")
  
  makespanners <- function(){
  cog_load <- c(2,3)
  control <- c(4,5)
  spans <- list(cog_load,control)
  names(spans) <- c("Cognitive Load","Control")
  spans
}

#test <- tb_count_perc(df3)
#tb_count_perc(df3a)



```


```{r S6tab1dumb1allHeinz,results = 'asis', include=FALSE}


apa_table(
   test
   , align = c("l", "l", "c", "c", "c")
   , caption = "Response to the critical slide depending on cognitive load (Heinz)"
   #, added_stub_head = "Response to critical slide"
   , col_spanners = makespanners()
   #, note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r}


y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")

z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
test


#y <- table(df3$condition,df3$Dumb_incl_string)
#y <- as.data.frame(y)
#colnames(y) <- c("condition","InCS","Freq")

# z <- as.data.frame(table(df3$condition,df3$Dumb_incl_string)/length(df3$gender)*2)
# perc <- z$Freq
# test <- cbind(y,perc)
# test$condition
# test


ab_graph <- function(){
  a <- df3[which(df3$condition==levels(as.factor(df3$condition))[1]),]
  b <- df3[which(df3$condition==levels(as.factor(df3$condition))[2]),]
  a#levels(as.factor(df3$condition))[1]
  
  ay <- as.data.frame(table(a$InCS,as.character(a$condition)))
  by <- as.data.frame(table(b$InCS,as.character(b$condition)))
  
  aperc <- ay$Freq/length(a$gender)
  ay <- cbind(ay,aperc)
  colnames(ay) <- c("InCS","condition","Freq","perc")
  
  bperc <- by$Freq/length(b$gender)
  by <- cbind(by,bperc)
  colnames(by) <- c("InCS","condition","Freq","perc")
  
  c <- rbind(ay,by)
  
  c
}

test <- ab_graph()



rm(y)
```


```{r S6ch5S6fig2criticalconditionbHeinz, fig.cap="Responses to critical slide depending on cognitive load (Heinz)", include=FALSE}


ggplot(test, aes(x=reorder(InCS), y=perc, fill=factor(condition,labels=c("Cognitive load","Control")))) +
  scale_y_continuous(limits = c(-.03,1),
                     labels = percent_format()
  )+ 
  geom_col(position = "dodge",
           color="black",
           size=.2
  )+
  geom_text(#family = "Times",
    size=4.2,
    aes( label = scales::percent(perc, accuracy = 1),
         y= perc ),
    stat= "identity",
    vjust = -.5,
    position = position_dodge(.9),
    fontface='plain'
  )+
  geom_text(#family = "Times", 
    size=4.2,
    aes(label = format(Freq),
        y= -3*(..count../100)/(..count..)),
    stat= "count",
    position = position_dodge(0.9),
    #vjust = -.05,
    fontface='plain'
  ) +
  xlab("Response to Critical Slide") +
  ylab("Percentage of participants selecting each response")+
  scale_x_discrete(labels=c("Reasons", "Dumbfounded","Nothing Wrong")) +
  scale_fill_grey(start = .5, end = .8) +
  labs(fill="Condition") +
  #theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
          size=12
        ),
        legend.text=element_text(#family="Times",
          size=8
        ),
        legend.title=element_text(#family="Times",
          size=10
        ),
        axis.text=element_text(#family="Times",
          colour = "black",
          size=8
        ),
        axis.ticks.x = element_blank(),
        axis.title=element_text(#family="Times",
          size=12
        ),
        strip.text=element_text(#family = "Times",
          size = 12
        ),
        #strip.background = element_rect(fill = "white"),
        legend.position="right")




```


```{r}
c <- chisq.test(table(df3$InCS,df3$condition))
rownames(rbind(c$observed,c$expected,c$stdres))



ps <- function(y){
  if(as.numeric(sqrt( y*y) ) >3.3) print(paste0(y,"**"), quote = FALSE)
  else if(as.numeric(sqrt( y*y) ) >1.96) print(paste0(y,"*"), quote = FALSE)
  else print(y)}


x <- c$stdres
x <- round(x, digits = 2)

lapply(x, ps)

#c$stdres <- round(c$stdres,digits=3)
#c$stdres <- ps(c$stdres)

ps(x[1])
ps(x[2])
ps(x[3])

x <- `colnames<-`(
  cbind.data.frame(c(ps(x[1]),ps(x[2]),ps(x[3])),
                   c(ps(x[4]),ps(x[5]),ps(x[6]))),
  c("cog_load","control")
)

rownames(x) <- row.names(c$observed)  

y <- rbind(round(c$observed), round(c$expected, digits = 2))

c(c$stdres[1])


res <- cbind(c("Observed count","","","Expected count","","","Standardised residuals","",""),
      c("Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong"),
      rbind(y,x)
      
      )

row.names(res) <- NULL
colnames(res) <- c("","","Cognitive Load","Control")




```



```{r S6tab1dumbHeinz,results = 'asis', include=FALSE}


apa_table(
   res
   , align = c("l", "l", "c", "c", "c")
   , caption = "Observed counts, expected counts, and standardised residuals for each response to the critical slide depending on cognitive load (Heinz)"
   #, added_stub_head = "Response to critical slide"
   #, col_spanners = makespanners()
   , note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


# Discussion

The present research aimed to add to the literature on moral judgments by offering new insights into factors that prompt moral dumbfounding. We hypothesized that under cognitive load, participants would be less likely to provide reasons and more likely to present as dumbfounded (or to select nothing wrong). When participants engaged in a secondary task while completing a dumbfounding task reason-giving was inhibited for three out of four scenarios tested. Overall we find evidence that in situations where the resources available for deliberation are limited (as when cognitive load is high), reason-giving is reduced, and moral dumbfounding is more likely. This key finding is consistent with previous work demonstrating that cognitive load inhibits deliberative responding [@deneys_dual_2006; @evans_rapid_2005].

## Implications, Limitations, and Future Directions

These studies offer new understandings of the phenomenon of moral dumbfounding. While our studies illustrate the complexity of attempting to understand moral judgments, we do demonstrate some reliable patterns that offer support to our core theoretically-informed hypotheses. Furthermore, these studies showcase a methodology for measuring dumbfounding under different empirical conditions, offering a path for future researchers to explore the role of other contextual and individual difference variables in influencing moral dumbfounding.

From a theoretical perspective, our findings are consistent with a dual-process explanation of moral dumbfounding, whereby dumbfounding occurs when an intuitive/habitual response is in conflict with a deliberative response [@evans_resolution_2007; again we note that the assumption of dual-processes is not necessarily required, and that this prediction is also consistent with the unimodel, @kruglanski_intuitive_2011; or categorization approaches @mchugh_moral_2022]. In line with existing theorizing on moral judgments [@cushman_action_2013; @mchugh_moral_2022; @railton_moral_2017], we propose that an individual may make an intuitive judgment and that subsequent attempts to identify reasons for this judgment occur through deliberation. If deliberation is unsuccessful and the individual does not revise their judgment, dumbfounding is observed. In support of this explanation, our studies demonstrated that by reducing the cognitive resources available for deliberation, reason-giving was reduced and dumbfounding increased.

Our results do display some unexplained variability, with the *classic* dumbfounding scenario (*Julie and Mark*) showing no significant change in responding with increased cognitive load (we note that the pilot studies used only this scenario and also showed mixed results). An exploratory follow-up test for equivalence did not provide evidence for the absence of an effect; thus, our results regarding *Julie and Mark* are inconclusive.

One potential explanation for this may point to an overall tendency for participants to be less likely to provide reasons for their judgment of *Julie and Mark* than for the other scenarios. This would be in line with its apparent standing as the *classic* dumbfounding scenario [@haidt_emotional_2001; @royzman_curious_2015]. Examination of Figure 3 seems to provide some support for this interpretation. In the control condition, the rate of providing reasons was lowest for *Julie and Mark*, and this remained descriptively lower than rates of reason-giving for both *Heinz* and *Jennifer* in the cognitive load conditions (i.e., rates of reason-giving for both *Heinz* and *Jennifer* were higher under cognitive load than rates of reason-giving in the control condition for *Julie and Mark*). It is possible that any effect of cognitive load on reason-giving was confounded by this lower base rate of reason-giving. We note however that this interpretation is not necessarily supported when the results for *Julie and Mark* are compared with the results for *Trolley*. That is, rates of reason-giving for Trolley under cognitive load were lower than rates of reason-giving for *Julie and Mark* in either condition. Future research should attempt to better understand these findings.

It is also possible that these inconclusive results reflect a lack of statistical power. Recall that a sample of *N* = 1966 was required to detect a small effect size (*V* = .07) with 80% power. It is possible that cognitive load does reduce reason-giving, even in the *Julie and Mark* scenario, but that our sub-sample of a sample of *N* = 412 did not have sufficient power to detect this effect. We cautiously present two reasons why this interpretation may be plausible. First, our equivalence test was sufficiently powered to detect equivalence at the level of *d* = .204, however, this failed to show equivalence. Second, all five pilot studies used the *Julie and Mark* dilemma, and while the results of these appear to be similarly inconclusive, the direction in the pattern of results remains consistent across all studies – that is the opposing pattern of results has not been shown in any study. None of the studies conducted showed an increase in reason-giving under cognitive load (even a non-significant increase).  

We note that while we did not find any significant differences in responding to the critical slide depending on performance for the cognitive load task, neither did we find evidence of equivalence. It is plausible that the quality of engagement with the secondary task will impact the influence of this secondary task on a moral judgment task, and this provides a further avenue for future research. 

It may be possible that some of the observed variability in our results can be attributed to methodological limitations. Classic studies of dual-process conflict are characterized by binary response options [an intuitive response contrasted with a deliberative response; @evans_resolution_2007], whereas our studies included three response options that varied in their relative amount of deliberation. As such the dumbfounding paradigm is more complex than classic binary response paradigms, and cognitive load manipulations may not be well suited for this additional complexity. It is also possible that this variability reflects a lack of statistical power to detect small effects for the specific scenario.

It is also possible that these results provide evidence that the conflict in dual-process explanation tested here is only part of the story, illustrating that moral dumbfounding displays high variability and context dependency [as with moral judgment more generally, see @mchugh_moral_2022]. For example, a further complication is that responses in the dumbfounding paradigm may involve competing intuitions. For example, participants may have intuitions relating to the nature of moral knowledge, such as moral judgments should be justifiable by reasons, that may become salient during the course of the study. This means that, in addition to experiencing a conflict between habitual and deliberative responding, participants may also experience competing intuitions. The relative salience of these competing intuitions may depend on a range of factors, including features of the scenario (e.g., severity/seriousness of the transgression, the kind of transgression), features of the characters in the scenario, personal familiarity with discourse around scenario content, and other factors such as current goals. Future research should unpack the influences of these competing intuitions.

One interesting finding that emerged that was not hypothesized was the apparent influence of cognitive load on participants' judgements. Under cognitive load, participants were significantly less harsh in their judgments (note that this appears to reflect judgments of lower extremity rather than a change in the valence of participants’ judgments). This was true for both initial judgments and revised judgments, suggesting that this is more than just an increased receptiveness to the counter-arguments under cognitive load (initial judgments were made before any counterarguments were presented). Future research should follow up on this finding, and investigate the influence of cognitive load on moral judgments more generally, e.g., does it only influence specific kinds of judgments (such as utilitarian judgments specifically, see Greene et al., 2008).   

Our findings have relevance for society more broadly. Moral considerations inform a range of behaviors and decisions, both at the individual level and at the societal level (Sinnott-Armstrong et al., 2010). It is likely that moral dumbfounding may be a contributing factor to moral disagreement on contentious issues. Our studies provide evidence that dumbfounding may be more prevalent in situations that constrain people’s ability to engage in deliberation. In practice, this suggests that when discussing contentious moral issues, disagreement through dumbfounding may be reduced by ensuring conditions suitable for deliberation (e.g., avoiding emotionally charged, high-pressure environments). Future research should build on this to test experimental manipulations that may help to reduce dumbfounding. Such a program of research may lead to the development of practical interventions that can reduce instances of dumbfounding in real-world situations. Examples of relevant experimental manipulations may draw on approaches such as construal level theory to encourage more abstract reasoning, e.g., through increased psychological/temporal distancing (e.g., Liberman et al., 2002). We note that attempts to test this will be similarly constrained by the methodological considerations identified above (three response options, competing intuitions).

While the studies presented here were in line with our theoretical predictions, we note that our samples were either student or online participants from Westernized countries, limiting the generalizability of our findings. While emerging research suggests that dumbfounding is observed in certain non-WEIRD populations [@mchugh_just_2023], future research should test if the explanation tested here generalizes beyond Western contexts.

# Conclusion
Moral dumbfounding occurs when people stubbornly maintain a moral judgment, even without reasons to support their judgments. To date, there are few studies that consider the causes of moral dumbfounding. Here, we test the idea that moral dumbfounding is more likely to occur when an individual is experiencing greater demands on their cognitive system, leaving less cognitive resources available for reasoning in complex moral dilemmas. The findings from the present research show that moral dumbfounding is more likely to occur under cognitive load, at least in some contexts. While these findings add new knowledge to the literature on moral dumbfounding, they also highlight the complexities of moral judgments. Further research is needed to better understand the factors that lead to dumbfounding, and, ultimately, how it might be reduced.



# References



<script src="https://unpkg.com/vanilla-back-to-top@7.2.0/dist/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 56,
  backgroundColor: '#3f51b5',
  textColor: '#fff'
})</script>
